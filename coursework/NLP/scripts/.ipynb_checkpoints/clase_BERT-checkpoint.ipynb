{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e836871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "remove_punct_map = dict.fromkeys(map(ord, string.punctuation))\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns',1000)\n",
    "from itertools import compress\n",
    "from nltk import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a39e99c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "012fd175",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9690b0",
   "metadata": {},
   "source": [
    "https://modelzoo.co/model/pytorch-pretrained-bert\n",
    "\n",
    "https://pytorch.org/hub/huggingface_pytorch-transformers/\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2019/09/demystifying-bert-groundbreaking-nlp-framework/\n",
    "\n",
    "https://towardsdatascience.com/tips-and-tricks-for-your-bert-based-applications-359c6b697f8e\n",
    "\n",
    "https://towardsdatascience.com/how-to-use-bert-from-the-hugging-face-transformer-library-d373a22b0209"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7816b2bf",
   "metadata": {},
   "source": [
    "###  Beto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67f7d92",
   "metadata": {},
   "source": [
    "https://github.com/dccuchile/beto/blob/master/config/cased_2M/vocab.txt\n",
    "\n",
    "Seguir instrucciones para descargar los archivos!!\n",
    "    \n",
    "https://colab.research.google.com/drive/1uRwg4UmPgYIqGYY4gW_Nsw9782GFJbPt#scrollTo=HhAqZLs3lwhW    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1fbb1cf-0aea-44ac-92d3-0bf944acdba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33f4d6c2-fd8c-455f-8d64-d7dbb142bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wget.download('https://users.dcc.uchile.cl/~jperez/beto/cased_2M/pytorch_weights.tar.gz') \n",
    "#wget.download('https://users.dcc.uchile.cl/~jperez/beto/cased_2M/vocab.txt') \n",
    "#wget.download('https://users.dcc.uchile.cl/~jperez/beto/cased_2M/config.json') \n",
    "#!tar -xzvf pytorch_weights.tar.gz   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e90d9376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a17d567",
   "metadata": {},
   "source": [
    "#### Usando BERT para tener embeddings (raw outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13a42c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa573a91",
   "metadata": {},
   "source": [
    "The bare Bert Model transformer outputting raw hidden-states "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62a217f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"pytorch\\\\\", do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b4b5683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bos',\n",
       " '##zados',\n",
       " '##trices',\n",
       " '300',\n",
       " 'visita',\n",
       " 'Somos',\n",
       " 'raro',\n",
       " '##tent',\n",
       " '64',\n",
       " 'financieras',\n",
       " 'Ing',\n",
       " 'integración',\n",
       " '##dice',\n",
       " 'vehículos',\n",
       " '##quia',\n",
       " 'reh',\n",
       " 'Dime',\n",
       " 'banco',\n",
       " 'habili',\n",
       " '##yendo']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tokenizer.vocab.keys())[6050:6070]\n",
    "#list(tokenizer.vocab.keys())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdc883ca-5f3a-47cc-b05b-dbbf44da26b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31002"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(tokenizer.vocab.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c042f4",
   "metadata": {},
   "source": [
    "BertTokenizer perform end-to-end tokenization, i.e. basic tokenization followed by WordPiece tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d96a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(\"pytorch\\\\\",output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7981c01f-a9b0-440f-b7fb-ab9689de4c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['¿', 'Quién', 'era', 'él', 'para', 'juzgar', '?']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize: Converts a string in a sequence of tokens (string), using the tokenizer. Split in words for word-based vocabulary \n",
    "# or sub-words for sub-word-based vocabularies (BPE/SentencePieces/WordPieces).\n",
    "word = \"banco\"\n",
    "#word = \"bancu\"\n",
    "word = '¿Quién era él para juzgar?'\n",
    "tokenizer.tokenize(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e530f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(word, return_tensors=\"pt\")     # pt for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0821d37c-066d-4540-9a24-934ee4bb5356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    4,  1067,  2363,  1538,  1611,  1110, 13778,  1064,     5]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05925031-8cc8-47f5-8045-bf920d8476f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    4,  1067,  2363,  1538,  1611,  1110, 13778,  1064,     5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9171a4b-016b-489d-a526-fc78898c6210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] ¿ Quién era él para juzgar? [SEP]'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08456546-a49f-46ec-90b6-cb2532eecb1a",
   "metadata": {},
   "source": [
    "Vemos que arroja nueve id, porque añade al comienzo y al final de la \"frase\" un caracter especial\n",
    "\n",
    "¿Qué son token_type_ids y attention_mask? Recordemos que BERT está preparado también para recibir pares de frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "012f076d-6a0f-4110-bea2-10be2b7b8540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] ¿ Quién era él para juzgar? [SEP] ¿ Quién era él para tener sus propias opiniones en el asunto? [SEP]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer('¿Quién era él para juzgar?','¿Quién era él para tener sus propias opiniones en el asunto?')  # argumentos por separado\n",
    "tokenizer.decode(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f738065-c6c3-4f24-8ad8-a1f2716747a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [4, 1067, 2363, 1538, 1611, 1110, 13778, 1064, 5, 1067, 2363, 1538, 1611, 1110, 1970, 1287, 6550, 8268, 1036, 1040, 4320, 1064, 5], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b66d59-dd4c-41b9-aef9-efbb8b1fb407",
   "metadata": {},
   "source": [
    "Lo anterior es útil para darle pares de frases, dado que hay tareas que pueden requerirlo (por ejemplo zero-shot-classifier). Por lo mismo, veamos que pasa si le damos más de dos frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c7da18c-6b41-4f2d-a620-db5e3b48dca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] ¿ Quién era él para juzgar? [SEP] ¿ Quién era él para tener sus propias opiniones en el asunto? [SEP]'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer('¿Quién era él para juzgar?','¿Quién era él para tener sus propias opiniones en el asunto?','hola hola') \n",
    "tokenizer.decode(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859907b-c6c2-4f2c-bc55-1ce5e7f74bc7",
   "metadata": {},
   "source": [
    "En cambio, si lo que quiero es procesar una lista de frases por separado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6edbb541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[4, 1067, 2363, 1538, 1611, 1110, 13778, 1064, 5, 1, 1, 1, 1, 1, 1], [4, 1067, 2363, 1538, 1611, 1110, 1970, 1287, 6550, 8268, 1036, 1040, 4320, 1064, 5]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(['¿Quién era él para juzgar?','¿Quién era él para tener sus propias opiniones en el asunto?'], padding=True)  # argumentos en lista\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19af5a17-cd57-4311-a1f3-00de2bc69ea1",
   "metadata": {},
   "source": [
    "Como las frases son de distinto largo (y esto va a ser una matriz más adelante), necesitamos que calcen los largos. Para ello,  o bien truncamos (cosa que no queremos, a menos que supere el largo permitido) o bien hacemos \"padding\". El mask es para hacer notar al modelo en qué tiene que fijarse (o en que no). Acá si admite más de dos frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4a7fb41-0314-42ff-b46a-5adfb6ca2310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[4, 1067, 2363, 1538, 1611, 1110, 13778, 1064, 5, 1, 1, 1, 1, 1, 1], [4, 1067, 2363, 1538, 1611, 1110, 1970, 1287, 6550, 8268, 1036, 1040, 4320, 1064, 5], [4, 9050, 9050, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(['¿Quién era él para juzgar?','¿Quién era él para tener sus propias opiniones en el asunto?','hola hola'], padding=True)  # argumentos en lista\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "362495ee-faea-4e5f-bcb3-dc128612462e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] hola hola [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenizer.decode(inputs['input_ids'][0])\n",
    "#tokenizer.decode(inputs['input_ids'][1])\n",
    "tokenizer.decode(inputs['input_ids'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d37d7b2",
   "metadata": {},
   "source": [
    "Entonces \n",
    "\n",
    "token_type_ids : also called segment IDs  \n",
    "attention mask : The attention mask is a binary tensor indicating the position of the padded indices so that the model does not attend to them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7995e95-a82b-4af4-a666-457958b3cea6",
   "metadata": {},
   "source": [
    "Ahora veamos la salida, el embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "add4c3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¿Quién era él para juzgar?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff5850e9-6d97-4972-8011-cccb0792660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(word, return_tensors=\"pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1db36206",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aea15c43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1237,  0.2803,  0.6217,  ..., -0.2897,  0.6623,  0.6892],\n",
       "         [-0.4657,  0.2487, -0.1177,  ...,  0.2439,  0.6109,  0.7491],\n",
       "         [-0.4191, -0.7333,  0.0412,  ..., -0.4169,  0.1598,  0.6122],\n",
       "         ...,\n",
       "         [-0.3142, -0.1232,  0.1890,  ..., -0.1837,  0.8170,  0.3507],\n",
       "         [-0.2474,  0.2841,  0.0095,  ...,  0.0677,  0.5647,  0.1738],\n",
       "         [-0.9872, -0.3595,  0.0244,  ..., -0.2530,  1.1619, -0.2488]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 9.5528e-01,  1.2369e-02, -2.0887e-01, -2.3035e-01,  3.8170e-02,\n",
       "         -2.3398e-01,  8.9570e-02, -9.8485e-01, -1.6933e-02, -3.5385e-01,\n",
       "         -7.1521e-01, -1.9591e-01,  1.0233e-01, -9.8851e-01, -2.3959e-02,\n",
       "          8.3479e-02, -2.7281e-02,  9.9625e-01,  1.4597e-01,  9.7896e-01,\n",
       "          2.5057e-01,  3.7788e-02, -9.9760e-01,  9.5620e-01, -9.9785e-01,\n",
       "          8.4532e-01, -8.5625e-01, -2.7185e-01, -2.5260e-01, -9.9153e-01,\n",
       "          2.5218e-01,  9.7068e-01, -2.7211e-02,  7.1304e-01, -1.1333e-01,\n",
       "          5.9167e-01,  1.4911e-01,  3.0053e-01,  6.4381e-01, -1.9160e-01,\n",
       "         -9.2276e-01, -6.2833e-02, -6.4206e-01,  2.5876e-02, -4.0004e-01,\n",
       "          1.1086e-01, -7.1981e-02,  1.4261e-01, -2.2328e-01, -1.9051e-02,\n",
       "         -2.4323e-02,  8.3193e-02, -3.3971e-03,  9.9894e-01,  2.0373e-02,\n",
       "          9.9780e-01, -1.4740e-01, -9.8730e-01, -5.3113e-03,  9.9613e-01,\n",
       "         -1.2250e-01, -9.8390e-01, -3.0281e-01, -9.6005e-01, -1.1456e-01,\n",
       "          9.0570e-01, -1.7222e-01,  1.8182e-01,  9.3723e-01, -7.2215e-01,\n",
       "         -9.9513e-01,  2.3693e-01,  1.9983e-01,  9.8985e-01,  9.5312e-02,\n",
       "          3.4926e-02,  9.9806e-01, -1.1211e-01, -6.1220e-01,  9.7146e-01,\n",
       "          9.8626e-01,  1.7306e-01,  1.9402e-01,  1.1244e-01, -1.0590e-01,\n",
       "         -1.3580e-01,  1.5379e-03, -1.8391e-01, -9.8632e-01,  9.7555e-01,\n",
       "          9.9777e-01, -3.0926e-02,  4.8757e-02, -2.2701e-01, -3.1931e-01,\n",
       "          9.9565e-01, -3.7903e-01, -1.2024e-01,  2.8837e-03,  9.7878e-01,\n",
       "         -8.9605e-01, -1.7611e-01,  1.0287e-01,  3.4586e-02,  9.9677e-01,\n",
       "         -7.3554e-01, -1.5640e-01,  2.4407e-01, -9.8478e-01,  7.9811e-01,\n",
       "         -9.4489e-01, -9.8366e-01,  3.4827e-02,  3.0859e-02, -4.2955e-02,\n",
       "         -9.8325e-01,  1.4085e-01, -2.1952e-01, -8.6692e-01,  9.3969e-01,\n",
       "          4.7787e-02,  9.9245e-01,  2.3189e-01,  9.4031e-01, -4.9630e-02,\n",
       "         -9.7246e-01, -9.9788e-01,  9.1123e-01, -1.7662e-02,  9.6130e-01,\n",
       "          9.8743e-01, -3.2881e-01, -8.5345e-01, -5.4394e-02, -9.2755e-02,\n",
       "         -9.9756e-01, -9.9890e-01,  1.4333e-01, -1.8457e-01,  9.6945e-02,\n",
       "          9.9606e-01, -9.9082e-01,  9.9745e-01, -7.1253e-02, -9.8409e-01,\n",
       "          9.5906e-01,  9.9669e-01,  1.0789e-02,  1.8599e-01, -7.1889e-01,\n",
       "          9.4045e-01,  5.9157e-01, -4.2075e-02,  3.4593e-02, -6.2092e-02,\n",
       "         -8.6132e-02,  2.0320e-02,  1.6595e-01, -2.1731e-02,  9.9237e-01,\n",
       "          2.3091e-01, -4.5930e-02, -3.7555e-02, -1.6906e-01,  1.4498e-01,\n",
       "         -8.0487e-01,  5.3964e-02, -3.1168e-01, -2.2293e-03,  1.8410e-01,\n",
       "          1.4973e-01, -8.0311e-01, -9.9588e-01,  7.5470e-02, -3.2948e-01,\n",
       "         -4.8281e-03,  9.9253e-01,  1.3224e-01, -8.9530e-01,  9.0730e-02,\n",
       "         -1.9771e-01, -5.7455e-01,  2.6511e-01,  7.8325e-03,  9.6376e-02,\n",
       "          2.6426e-01,  9.2300e-01,  9.8611e-01, -8.3975e-01,  6.7583e-02,\n",
       "         -9.3671e-02, -3.1837e-02,  4.0913e-03,  1.0684e-01,  9.4321e-01,\n",
       "          1.6410e-01,  1.1763e-01,  6.7520e-01, -9.5671e-01,  9.0622e-01,\n",
       "          1.8628e-02, -9.9827e-01, -1.1180e-01,  8.7792e-02, -9.5822e-01,\n",
       "         -5.3619e-02, -7.7642e-01, -8.2842e-01,  8.8776e-01,  9.4449e-02,\n",
       "          7.8955e-02, -8.9596e-01,  7.9141e-01,  9.1814e-04, -9.2540e-01,\n",
       "          1.5821e-01, -2.9516e-01, -9.7482e-02, -2.6023e-01,  8.9354e-01,\n",
       "         -1.6212e-01,  1.0963e-01, -8.7451e-01,  7.7702e-02,  9.8942e-01,\n",
       "         -9.9188e-01,  8.8772e-01,  9.0441e-01, -9.8725e-01,  2.2069e-01,\n",
       "         -9.2657e-01,  9.9452e-01,  1.5980e-01,  9.8409e-02,  8.5473e-01,\n",
       "          2.4419e-01, -1.7898e-02,  4.2681e-03, -9.8699e-01,  8.5855e-01,\n",
       "          1.1542e-02, -4.9898e-02,  8.9705e-03, -9.3826e-01, -9.7739e-01,\n",
       "          8.5920e-01, -1.7708e-01, -7.2107e-01,  1.9595e-01, -1.8715e-01,\n",
       "         -9.7985e-01, -9.7586e-01,  1.0208e-01, -9.5767e-01,  5.9807e-02,\n",
       "         -8.7398e-01,  1.1736e-02,  3.5622e-02,  3.5868e-01,  2.0721e-01,\n",
       "         -5.3984e-01,  1.0925e-01,  2.9120e-03,  7.1897e-01,  9.0938e-01,\n",
       "          1.1488e-01,  8.9162e-01, -2.3462e-01, -9.9682e-01, -2.5362e-01,\n",
       "         -1.4473e-01, -9.6851e-01,  1.4037e-01, -1.8954e-01, -4.9849e-01,\n",
       "         -9.9995e-01,  2.3352e-02,  9.6523e-01, -8.1957e-02,  1.1493e-02,\n",
       "         -8.7990e-01, -2.0903e-01,  4.2360e-01,  1.6656e-02, -8.7259e-01,\n",
       "          1.3313e-01, -9.8535e-02,  9.9318e-01, -1.1462e-01, -7.7519e-02,\n",
       "         -7.7518e-01,  2.2643e-01, -8.5158e-01, -6.7762e-02,  7.7602e-01,\n",
       "         -9.9001e-02, -8.3505e-01,  4.7501e-01,  1.0276e-01, -2.6568e-02,\n",
       "          2.0639e-02,  9.9998e-01,  9.7030e-01, -6.3507e-02, -2.1952e-01,\n",
       "          1.0024e-01,  1.8462e-01,  9.9162e-01, -6.3344e-02,  8.2587e-01,\n",
       "          1.0425e-01, -2.5505e-01, -9.9833e-01,  2.4022e-02, -3.8349e-01,\n",
       "         -2.6856e-01,  2.0354e-01, -1.0255e-01, -3.5507e-01,  1.6199e-02,\n",
       "         -3.8303e-03, -1.1685e-01,  7.1031e-02, -7.6307e-01,  2.3499e-02,\n",
       "         -1.0152e-01, -9.1377e-01, -4.5503e-02,  8.9029e-02,  1.6196e-01,\n",
       "         -9.9211e-01, -9.7271e-01,  9.2446e-01,  9.9775e-01, -4.6105e-01,\n",
       "          4.4924e-01, -5.6030e-03, -1.8939e-02,  1.2992e-02, -1.6050e-02,\n",
       "         -9.9216e-01,  9.3826e-01, -9.8811e-01,  9.2353e-01, -3.9615e-02,\n",
       "          6.9232e-01, -1.7340e-01,  9.6725e-01,  1.0032e-01,  6.5028e-01,\n",
       "         -1.2609e-01,  3.8171e-01, -3.8033e-03,  9.7875e-01, -2.0783e-01,\n",
       "          1.2789e-04, -7.5709e-02, -7.0150e-02,  1.2984e-01, -3.1168e-01,\n",
       "         -9.9537e-01, -4.7805e-02,  1.0532e-01,  6.2958e-01,  7.7142e-02,\n",
       "          6.7311e-02,  9.6887e-01,  2.8995e-03,  4.8730e-02,  1.1312e-01,\n",
       "          8.7330e-01, -3.4311e-02, -1.8028e-02, -9.9462e-02,  9.8028e-01,\n",
       "          8.8742e-03,  2.4882e-01,  3.3145e-01,  9.7855e-02,  6.7978e-01,\n",
       "          4.0462e-02,  9.9989e-01,  9.1102e-01, -4.2675e-01, -3.0868e-01,\n",
       "         -9.2720e-01,  9.2719e-01, -1.3091e-01,  9.2436e-01,  9.9897e-01,\n",
       "         -9.9490e-01, -9.7546e-02, -1.1236e-01,  8.0573e-02,  9.8448e-01,\n",
       "          1.3316e-01, -2.4750e-02,  9.9932e-01, -8.4469e-01, -9.4444e-01,\n",
       "         -3.2115e-01, -6.1398e-01,  4.5111e-02, -8.6306e-01, -1.5083e-01,\n",
       "          3.9611e-02, -7.6600e-02,  1.0139e-03,  8.2580e-02,  2.4137e-01,\n",
       "         -4.5361e-02, -7.1156e-02,  7.2615e-02,  9.8131e-01, -9.5913e-01,\n",
       "          9.9976e-01,  1.4960e-01,  1.4246e-01, -8.2865e-02,  9.8651e-01,\n",
       "          1.0900e-01, -9.6213e-01, -5.8076e-01, -2.6039e-02, -5.8807e-02,\n",
       "          1.5967e-01,  2.7290e-01, -2.7337e-01,  5.6661e-02, -9.9972e-01,\n",
       "         -1.0651e-01, -1.2105e-01, -9.9086e-01,  9.9964e-01,  2.2485e-01,\n",
       "         -9.1938e-01,  2.2986e-01, -5.7894e-01,  8.8665e-01,  4.8855e-02,\n",
       "         -3.4510e-02, -3.4375e-03,  8.9776e-01, -8.6969e-02,  9.9691e-01,\n",
       "         -9.7672e-02, -3.5754e-02,  8.9483e-02, -1.0302e-01,  9.9857e-01,\n",
       "          9.6231e-01, -8.4433e-01, -2.6508e-02,  6.4006e-03,  2.2554e-01,\n",
       "          5.3740e-03, -9.1867e-01,  1.3611e-01,  5.4295e-02, -2.3820e-01,\n",
       "          1.9897e-01,  5.9066e-01,  6.9662e-02,  3.6824e-01,  9.2925e-01,\n",
       "         -3.0784e-01,  7.4069e-02, -2.8389e-02, -8.3742e-02, -3.2265e-01,\n",
       "          9.9934e-01, -2.0317e-01,  9.7985e-01, -2.2035e-01,  9.5821e-01,\n",
       "          4.4657e-01,  9.4733e-01,  8.7092e-01, -2.3677e-01,  1.4136e-02,\n",
       "          8.6991e-01, -2.9546e-01,  2.1259e-01,  8.9093e-01,  2.3647e-01,\n",
       "          1.4939e-01, -1.8939e-01,  1.7762e-01,  1.8069e-01,  9.8861e-01,\n",
       "         -8.9374e-01, -6.5747e-02, -2.3945e-02,  9.8479e-01,  4.8041e-02,\n",
       "          4.7560e-02,  1.5855e-01,  7.5474e-02, -1.5832e-01,  9.6255e-01,\n",
       "         -2.1672e-01, -9.8974e-01, -7.9805e-02, -8.4763e-02,  1.2954e-01,\n",
       "          9.5035e-02,  8.2128e-02, -1.0241e-01, -2.4321e-01,  9.8662e-01,\n",
       "          2.4456e-02,  3.2573e-02,  1.3163e-01, -1.1565e-01, -4.8930e-03,\n",
       "          9.9853e-01, -9.0664e-02,  1.3034e-01, -2.5123e-01,  1.9994e-02,\n",
       "         -7.7072e-02, -9.2543e-01, -2.1169e-01, -4.3260e-02,  7.5089e-02,\n",
       "          8.9249e-03,  7.3935e-03,  4.9327e-01,  1.0883e-01, -9.8124e-01,\n",
       "         -3.2782e-01,  3.3588e-01,  1.0334e-01,  2.3283e-01, -1.2443e-01,\n",
       "         -9.7583e-01,  1.2413e-02, -9.9705e-01, -1.0696e-01, -2.0789e-01,\n",
       "          9.3900e-01,  2.6825e-01, -9.6533e-01,  8.6829e-01, -9.8577e-01,\n",
       "         -6.4788e-02, -5.1820e-01,  2.2202e-02, -8.2409e-02,  7.6452e-02,\n",
       "          5.2881e-01, -1.6467e-01, -1.6773e-01,  1.9526e-01, -6.5658e-02,\n",
       "         -5.5407e-02,  1.4546e-02, -6.9407e-02,  6.6254e-02, -3.3784e-01,\n",
       "         -3.2627e-03,  9.3116e-02,  9.7456e-01, -6.9015e-01,  9.5994e-01,\n",
       "         -6.3776e-01, -3.6737e-01, -3.6871e-02, -4.3236e-01, -8.2561e-02,\n",
       "          9.8735e-01, -3.5843e-02, -6.1940e-02, -4.1743e-01, -1.3268e-01,\n",
       "         -1.2533e-01, -1.3456e-01,  3.3274e-01,  4.9788e-01, -2.3789e-02,\n",
       "          1.2703e-01, -3.0291e-02,  7.9936e-02, -4.1650e-01, -1.0918e-01,\n",
       "          7.6758e-02,  1.0872e-01,  9.0315e-01,  8.5980e-01,  6.3015e-01,\n",
       "          9.1029e-01,  6.8856e-01,  2.2703e-01,  3.0473e-01,  2.1818e-02,\n",
       "          7.5927e-01, -7.8648e-01,  9.8640e-01,  6.2868e-01, -9.1016e-01,\n",
       "         -9.6559e-01,  7.5334e-02,  8.3694e-02, -1.4406e-01, -1.1050e-02,\n",
       "         -9.1675e-01, -1.8296e-01,  5.7030e-02, -1.3688e-01,  1.6032e-01,\n",
       "          9.9961e-01,  1.6747e-02,  2.8037e-01, -8.6013e-01, -2.3197e-01,\n",
       "          1.8806e-01, -9.6046e-02,  1.3165e-02,  8.9568e-01,  1.1286e-01,\n",
       "         -2.9016e-02,  9.7472e-01,  1.7210e-01,  6.3968e-01,  5.1452e-02,\n",
       "         -1.3567e-01, -8.8666e-01,  1.0657e-01,  2.4561e-01, -5.7038e-01,\n",
       "          4.8086e-02,  9.0678e-01, -1.0523e-02,  1.5917e-02, -6.7601e-02,\n",
       "          9.9232e-01,  4.8411e-02, -1.5960e-01, -4.1171e-02, -4.1828e-02,\n",
       "         -4.4863e-01, -4.9493e-01,  5.7720e-02,  6.8388e-01,  9.1415e-01,\n",
       "         -6.2050e-03,  2.6059e-01,  9.9317e-01,  9.9096e-01, -2.7744e-01,\n",
       "         -1.9266e-01,  6.2403e-02,  1.4848e-01,  3.2880e-02,  9.0301e-01,\n",
       "         -7.9391e-01, -9.9983e-01,  8.9471e-01, -8.2222e-01, -9.9302e-01,\n",
       "          1.2557e-01,  3.1877e-01,  2.0411e-03, -9.9991e-01, -2.9160e-01,\n",
       "         -9.9806e-01,  2.2475e-02, -9.9003e-01, -9.9902e-01,  6.1384e-01,\n",
       "          6.2365e-02, -1.5170e-02, -1.3950e-02,  9.0361e-01,  9.9544e-01,\n",
       "          7.7777e-01,  7.1371e-02,  1.9215e-02, -4.2764e-01,  6.0612e-02,\n",
       "         -5.0404e-01,  9.7627e-01, -3.6082e-02, -1.4449e-02, -9.4164e-01,\n",
       "         -9.9145e-01, -1.4768e-01,  1.6196e-01,  1.9001e-01, -2.2071e-01,\n",
       "          6.9883e-01, -1.1567e-01, -1.2232e-01, -9.8503e-01,  6.1199e-02,\n",
       "          9.7015e-01,  7.6558e-02,  9.9729e-01, -1.2539e-01, -1.4037e-01,\n",
       "         -9.9735e-01, -9.9699e-01,  1.3759e-01, -9.9140e-01,  7.3642e-01,\n",
       "         -3.3577e-02, -9.4239e-01, -4.0131e-02,  2.0729e-01, -1.4368e-01,\n",
       "         -1.9366e-01,  9.4556e-02,  4.8495e-01,  9.8695e-01,  2.2274e-01,\n",
       "          9.4987e-01,  1.9852e-02, -2.1603e-01, -1.4797e-01, -9.9969e-01,\n",
       "          9.9420e-01,  9.6138e-01,  1.5025e-01,  9.6257e-01,  3.0651e-02,\n",
       "          9.4406e-02,  1.3324e-02,  2.8227e-01, -8.7615e-01,  2.0756e-01,\n",
       "         -1.0399e-01, -8.8937e-02,  2.0397e-01, -2.3455e-01,  9.8843e-03,\n",
       "         -5.1797e-02, -2.4749e-01,  5.9976e-02,  1.3852e-01,  6.5996e-02,\n",
       "         -1.0532e-01,  1.2950e-03,  9.7350e-01, -4.2830e-02, -9.6177e-01,\n",
       "         -9.5209e-01, -1.5286e-01, -7.5582e-01,  9.6712e-01, -9.8710e-01,\n",
       "          9.5621e-01,  2.3835e-01, -4.5796e-01,  9.9446e-01, -9.0995e-01,\n",
       "          8.1926e-02, -7.0081e-02, -9.2415e-01, -1.2806e-01, -9.7976e-01,\n",
       "          9.3865e-01, -2.3240e-02,  9.5668e-02, -9.3979e-01,  2.0148e-01,\n",
       "          7.2400e-01, -2.0064e-01, -2.7446e-01]], grad_fn=<TanhBackward0>), hidden_states=(tensor([[[ 0.0608,  0.2993,  0.0115,  ...,  0.0999,  0.0082, -0.1987],\n",
       "         [ 0.5044,  1.7119, -0.6341,  ...,  0.2854,  0.3628,  1.0462],\n",
       "         [-0.7312, -0.3984, -0.7442,  ..., -1.3566,  0.2925,  0.2997],\n",
       "         ...,\n",
       "         [ 0.6574,  0.5871, -1.1026,  ...,  0.2151, -0.7084,  0.7364],\n",
       "         [ 0.2365, -0.1930, -1.0301,  ...,  0.0329,  0.4225, -0.7136],\n",
       "         [ 0.1659,  0.0441,  0.0766,  ..., -0.2411,  0.4139,  0.1342]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0181, -0.1076,  0.0097,  ..., -0.0430, -0.0142, -0.2207],\n",
       "         [ 0.4965,  1.4999, -0.7707,  ...,  0.5553,  0.0043,  1.2468],\n",
       "         [-0.4535, -0.6909, -0.4555,  ..., -1.7199,  0.2181, -0.2042],\n",
       "         ...,\n",
       "         [ 0.9583,  0.6662, -1.0942,  ...,  0.0871, -0.7676,  0.8305],\n",
       "         [ 0.1050, -0.5544, -1.0068,  ...,  0.0138,  0.4663, -0.7715],\n",
       "         [ 0.1488,  0.0790, -0.1097,  ..., -0.4080,  0.3653,  0.5044]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1043, -0.1069, -0.0957,  ..., -0.1605,  0.1473, -0.3970],\n",
       "         [ 0.0473,  1.0963, -1.1150,  ...,  0.6021, -0.5058,  1.1164],\n",
       "         [-0.4371, -0.9653, -0.0097,  ..., -1.2727, -0.3911, -0.4583],\n",
       "         ...,\n",
       "         [ 0.5990,  0.6320, -0.9506,  ...,  0.2922, -0.6147,  0.8743],\n",
       "         [ 0.0414, -0.3977, -0.8901,  ..., -0.0199,  0.3218, -0.8195],\n",
       "         [ 0.4116,  0.2776,  0.1881,  ..., -0.4943,  0.2259, -0.0793]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.3306, -0.0641,  0.0586,  ..., -0.3586,  0.3236, -0.2949],\n",
       "         [ 0.1165,  1.3847, -0.6565,  ...,  0.6473, -0.5877,  1.2650],\n",
       "         [-0.0798, -0.9199,  0.2308,  ..., -1.3246, -0.7255, -0.2177],\n",
       "         ...,\n",
       "         [ 0.2159,  0.7803, -0.7006,  ...,  0.2518, -0.7046,  1.0523],\n",
       "         [-0.0226, -0.2012, -0.4791,  ...,  0.3072, -0.1444, -0.9740],\n",
       "         [ 0.1144,  0.4596,  0.1403,  ..., -0.4678,  0.2280, -0.2170]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.5059, -0.3326,  0.4700,  ..., -0.4508,  0.1426, -0.1788],\n",
       "         [-0.0332,  1.1284, -0.0907,  ...,  0.8935, -0.3595,  0.9571],\n",
       "         [ 0.1783, -1.3292,  0.6176,  ..., -0.9731, -0.3017,  0.1022],\n",
       "         ...,\n",
       "         [-0.1328, -0.0092, -0.2342,  ...,  0.1854, -0.0098,  1.2672],\n",
       "         [-0.0429, -0.3709, -0.1281,  ...,  0.5592, -0.2288, -0.9795],\n",
       "         [ 0.3948, -0.0163,  0.4307,  ..., -0.5427,  0.1642, -0.3836]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.6968, -0.2663,  0.2159,  ..., -0.8563,  0.1483,  0.0499],\n",
       "         [-0.0271,  0.8916, -0.1461,  ...,  0.6810,  0.0386,  1.3053],\n",
       "         [ 0.1561, -1.1168,  0.1628,  ..., -1.0569,  0.2775,  0.4480],\n",
       "         ...,\n",
       "         [-0.7061,  0.1963, -0.2042,  ..., -0.2353,  0.4493,  0.9169],\n",
       "         [-0.2406, -0.3166, -0.1502,  ..., -0.2156, -0.1463, -0.8138],\n",
       "         [ 0.4802,  0.0144,  0.1236,  ..., -0.5902,  0.1434, -0.0752]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[-0.4083, -0.4251,  0.4448,  ..., -0.7379,  0.0194,  0.0653],\n",
       "         [ 0.0885,  0.2956,  0.1536,  ...,  0.6529,  0.0145,  0.9314],\n",
       "         [ 0.2648, -1.4518,  0.2712,  ..., -0.9393,  0.2453,  0.3616],\n",
       "         ...,\n",
       "         [-0.7018,  0.1229,  0.0871,  ..., -0.3768,  0.8822,  0.6812],\n",
       "         [-0.1943, -0.2484, -0.0378,  ..., -0.1963,  0.1854, -0.6277],\n",
       "         [-0.0750, -0.0957, -0.1416,  ..., -0.5696,  0.3093, -0.0532]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0207, -0.2146,  0.4922,  ..., -0.7480,  0.1034,  0.4806],\n",
       "         [ 0.1456,  0.2713,  0.4480,  ...,  0.8693,  0.4132,  1.0908],\n",
       "         [-0.4951, -1.8097,  1.1180,  ..., -0.5572, -0.3359,  0.5252],\n",
       "         ...,\n",
       "         [-0.8921, -0.0708,  0.0584,  ..., -0.1703,  1.1100,  0.7955],\n",
       "         [-0.2942,  0.0353,  0.2268,  ..., -0.2683,  0.1920, -0.2662],\n",
       "         [-0.0024,  0.0281, -0.1364,  ..., -0.2930,  0.3005,  0.0337]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 1.0580e-01,  3.1153e-01,  4.5195e-01,  ..., -6.1409e-01,\n",
       "           2.5671e-01,  2.8353e-01],\n",
       "         [ 7.9980e-02,  7.8049e-01,  3.6350e-01,  ...,  6.2933e-01,\n",
       "           3.0198e-01,  9.2505e-01],\n",
       "         [-2.3318e-01, -1.7653e+00,  5.9700e-01,  ..., -2.1991e-01,\n",
       "           5.5552e-03,  5.8612e-01],\n",
       "         ...,\n",
       "         [-1.1045e+00,  2.7394e-02, -2.9455e-02,  ..., -2.6397e-01,\n",
       "           1.1165e+00,  5.0499e-01],\n",
       "         [-1.2087e-01,  6.3717e-01,  1.8023e-01,  ..., -2.0041e-01,\n",
       "           5.2424e-01, -2.5031e-01],\n",
       "         [-1.7494e-02,  4.0796e-04, -3.8735e-03,  ..., -1.1344e-01,\n",
       "           5.3749e-03, -7.1622e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.0940,  0.5585,  0.4514,  ..., -0.4928,  0.6419,  0.4978],\n",
       "         [-0.1626,  1.0802, -0.0170,  ...,  0.7644,  0.8830,  1.5876],\n",
       "         [-0.3222, -1.8629,  0.9668,  ..., -0.8411, -0.0283,  0.7657],\n",
       "         ...,\n",
       "         [-1.2856,  0.1763, -0.1200,  ..., -0.4085,  1.1574,  0.7303],\n",
       "         [-0.2969,  1.0408, -0.1954,  ..., -0.1053,  0.5946, -0.4147],\n",
       "         [ 0.0044,  0.0377, -0.0654,  ..., -0.1082, -0.0120, -0.0725]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.3652,  0.4774,  0.4451,  ..., -0.2223,  0.3103,  0.6043],\n",
       "         [-0.5683,  0.9167,  0.0394,  ...,  0.6335,  0.7695,  1.4511],\n",
       "         [-0.2780, -1.1997,  0.4220,  ..., -0.3790,  0.1355,  0.8063],\n",
       "         ...,\n",
       "         [-1.0104,  0.1470,  0.0802,  ..., -0.4061,  1.1102,  0.5280],\n",
       "         [-0.2325,  0.9078,  0.0046,  ..., -0.0217,  0.5461, -0.1169],\n",
       "         [ 0.0417,  0.0127,  0.0147,  ..., -0.0536, -0.0133, -0.0636]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), tensor([[[ 3.7468e-01,  5.4335e-01,  6.9224e-01,  ..., -3.1812e-01,\n",
       "           5.6896e-01,  7.3585e-01],\n",
       "         [-2.3994e-01,  6.8969e-01,  2.8133e-01,  ...,  6.3491e-01,\n",
       "           7.2759e-01,  9.1228e-01],\n",
       "         [-2.5194e-01, -9.7642e-01,  7.2050e-01,  ...,  3.7923e-04,\n",
       "           4.4741e-02,  8.6301e-01],\n",
       "         ...,\n",
       "         [-7.0167e-01,  4.2465e-03,  5.3665e-01,  ..., -4.1478e-01,\n",
       "           1.3309e+00,  3.8026e-01],\n",
       "         [-1.1598e-01,  7.2518e-01,  2.3942e-01,  ...,  1.4962e-01,\n",
       "           6.7391e-01,  5.1359e-02],\n",
       "         [ 2.6372e-02,  2.1763e-02,  7.3815e-03,  ..., -4.1155e-02,\n",
       "           9.8487e-03, -5.6295e-02]]], grad_fn=<NativeLayerNormBackward0>), tensor([[[ 0.1237,  0.2803,  0.6217,  ..., -0.2897,  0.6623,  0.6892],\n",
       "         [-0.4657,  0.2487, -0.1177,  ...,  0.2439,  0.6109,  0.7491],\n",
       "         [-0.4191, -0.7333,  0.0412,  ..., -0.4169,  0.1598,  0.6122],\n",
       "         ...,\n",
       "         [-0.3142, -0.1232,  0.1890,  ..., -0.1837,  0.8170,  0.3507],\n",
       "         [-0.2474,  0.2841,  0.0095,  ...,  0.0677,  0.5647,  0.1738],\n",
       "         [-0.9872, -0.3595,  0.0244,  ..., -0.2530,  1.1619, -0.2488]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)), past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e96a8",
   "metadata": {},
   "source": [
    "\n",
    "pooler_output:  is the embedding of the [CLS] special token. In many cases, it is considered a valid representation of the complete sentence. Since the embeddings from the BERT model at the output layer are known to be contextual embeddings, the output of the 1st token, i.e, [CLS] token would have captured sufficient context. Hence, the authors of BERT paper found it sufficient to use only the output from the 1st token for few tasks such as classification.\n",
    "\n",
    "last_hidden_state: contains the final embeddings of all tokens in the sentence from the last hidden state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e7964f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vect = outputs.pooler_output.detach().numpy()  # esto último para que esté en formato vector y no en formato tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f043e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.55284238e-01,  1.23691568e-02, -2.08870038e-01,\n",
       "        -2.30350167e-01,  3.81696448e-02, -2.33978584e-01,\n",
       "         8.95695165e-02, -9.84853745e-01, -1.69333462e-02,\n",
       "        -3.53854299e-01, -7.15207160e-01, -1.95907146e-01,\n",
       "         1.02327757e-01, -9.88508821e-01, -2.39591151e-02,\n",
       "         8.34785625e-02, -2.72806957e-02,  9.96245265e-01,\n",
       "         1.45972654e-01,  9.78958726e-01,  2.50569224e-01,\n",
       "         3.77875865e-02, -9.97599304e-01,  9.56195951e-01,\n",
       "        -9.97847676e-01,  8.45317423e-01, -8.56252551e-01,\n",
       "        -2.71851748e-01, -2.52600253e-01, -9.91526723e-01,\n",
       "         2.52175421e-01,  9.70682740e-01, -2.72110254e-02,\n",
       "         7.13044941e-01, -1.13330409e-01,  5.91670930e-01,\n",
       "         1.49106100e-01,  3.00525159e-01,  6.43807948e-01,\n",
       "        -1.91597626e-01, -9.22760665e-01, -6.28330931e-02,\n",
       "        -6.42057836e-01,  2.58758012e-02, -4.00035530e-01,\n",
       "         1.10855967e-01, -7.19806999e-02,  1.42610595e-01,\n",
       "        -2.23275512e-01, -1.90508179e-02, -2.43227780e-02,\n",
       "         8.31930265e-02, -3.39709409e-03,  9.98939931e-01,\n",
       "         2.03732587e-02,  9.97799933e-01, -1.47402257e-01,\n",
       "        -9.87297654e-01, -5.31127909e-03,  9.96133208e-01,\n",
       "        -1.22501098e-01, -9.83903170e-01, -3.02811742e-01,\n",
       "        -9.60050762e-01, -1.14556052e-01,  9.05695558e-01,\n",
       "        -1.72224715e-01,  1.81823596e-01,  9.37227368e-01,\n",
       "        -7.22150624e-01, -9.95133400e-01,  2.36928955e-01,\n",
       "         1.99834093e-01,  9.89847839e-01,  9.53120068e-02,\n",
       "         3.49261276e-02,  9.98056412e-01, -1.12106666e-01,\n",
       "        -6.12197578e-01,  9.71458256e-01,  9.86259103e-01,\n",
       "         1.73062980e-01,  1.94016472e-01,  1.12441674e-01,\n",
       "        -1.05901040e-01, -1.35800108e-01,  1.53786247e-03,\n",
       "        -1.83908015e-01, -9.86320496e-01,  9.75551784e-01,\n",
       "         9.97773349e-01, -3.09264846e-02,  4.87569049e-02,\n",
       "        -2.27008879e-01, -3.19311410e-01,  9.95648205e-01,\n",
       "        -3.79027039e-01, -1.20237306e-01,  2.88366294e-03,\n",
       "         9.78782356e-01, -8.96053493e-01, -1.76107064e-01,\n",
       "         1.02866873e-01,  3.45863476e-02,  9.96766925e-01,\n",
       "        -7.35538363e-01, -1.56401679e-01,  2.44067922e-01,\n",
       "        -9.84777093e-01,  7.98105896e-01, -9.44887280e-01,\n",
       "        -9.83664095e-01,  3.48265208e-02,  3.08591276e-02,\n",
       "        -4.29554395e-02, -9.83246684e-01,  1.40848160e-01,\n",
       "        -2.19516009e-01, -8.66918623e-01,  9.39689696e-01,\n",
       "         4.77873273e-02,  9.92454231e-01,  2.31893912e-01,\n",
       "         9.40311253e-01, -4.96300757e-02, -9.72459137e-01,\n",
       "        -9.97875333e-01,  9.11233723e-01, -1.76623613e-02,\n",
       "         9.61303115e-01,  9.87425387e-01, -3.28805417e-01,\n",
       "        -8.53447556e-01, -5.43938950e-02, -9.27550942e-02,\n",
       "        -9.97562468e-01, -9.98900115e-01,  1.43329710e-01,\n",
       "        -1.84568644e-01,  9.69447345e-02,  9.96055186e-01,\n",
       "        -9.90815282e-01,  9.97453511e-01, -7.12533817e-02,\n",
       "        -9.84088838e-01,  9.59064364e-01,  9.96690929e-01,\n",
       "         1.07891038e-02,  1.85994014e-01, -7.18887210e-01,\n",
       "         9.40445781e-01,  5.91572106e-01, -4.20745946e-02,\n",
       "         3.45933661e-02, -6.20923042e-02, -8.61320943e-02,\n",
       "         2.03203391e-02,  1.65945515e-01, -2.17311680e-02,\n",
       "         9.92374361e-01,  2.30908379e-01, -4.59304117e-02,\n",
       "        -3.75552364e-02, -1.69062674e-01,  1.44975811e-01,\n",
       "        -8.04872751e-01,  5.39643839e-02, -3.11677903e-01,\n",
       "        -2.22925236e-03,  1.84103459e-01,  1.49727166e-01,\n",
       "        -8.03112626e-01, -9.95881617e-01,  7.54695609e-02,\n",
       "        -3.29479516e-01, -4.82805492e-03,  9.92529809e-01,\n",
       "         1.32242054e-01, -8.95297468e-01,  9.07298848e-02,\n",
       "        -1.97712407e-01, -5.74554741e-01,  2.65109420e-01,\n",
       "         7.83246197e-03,  9.63755846e-02,  2.64260024e-01,\n",
       "         9.22997892e-01,  9.86114919e-01, -8.39747965e-01,\n",
       "         6.75829276e-02, -9.36707482e-02, -3.18373144e-02,\n",
       "         4.09127446e-03,  1.06837958e-01,  9.43205714e-01,\n",
       "         1.64102793e-01,  1.17634185e-01,  6.75203979e-01,\n",
       "        -9.56705213e-01,  9.06217396e-01,  1.86284762e-02,\n",
       "        -9.98270988e-01, -1.11801781e-01,  8.77917185e-02,\n",
       "        -9.58218038e-01, -5.36187030e-02, -7.76415050e-01,\n",
       "        -8.28423262e-01,  8.87756467e-01,  9.44487825e-02,\n",
       "         7.89545551e-02, -8.95958006e-01,  7.91407764e-01,\n",
       "         9.18138539e-04, -9.25404966e-01,  1.58209950e-01,\n",
       "        -2.95156240e-01, -9.74820256e-02, -2.60226846e-01,\n",
       "         8.93541634e-01, -1.62121460e-01,  1.09633282e-01,\n",
       "        -8.74505639e-01,  7.77018890e-02,  9.89421308e-01,\n",
       "        -9.91883039e-01,  8.87719572e-01,  9.04405653e-01,\n",
       "        -9.87246692e-01,  2.20689297e-01, -9.26566720e-01,\n",
       "         9.94520545e-01,  1.59799919e-01,  9.84087661e-02,\n",
       "         8.54725003e-01,  2.44193166e-01, -1.78982690e-02,\n",
       "         4.26813401e-03, -9.86986995e-01,  8.58551264e-01,\n",
       "         1.15420092e-02, -4.98984642e-02,  8.97053257e-03,\n",
       "        -9.38262820e-01, -9.77391124e-01,  8.59196842e-01,\n",
       "        -1.77078933e-01, -7.21066475e-01,  1.95954219e-01,\n",
       "        -1.87151387e-01, -9.79853630e-01, -9.75860775e-01,\n",
       "         1.02082811e-01, -9.57665324e-01,  5.98071516e-02,\n",
       "        -8.73980463e-01,  1.17359906e-02,  3.56221981e-02,\n",
       "         3.58683497e-01,  2.07207963e-01, -5.39840817e-01,\n",
       "         1.09249793e-01,  2.91202706e-03,  7.18965232e-01,\n",
       "         9.09381390e-01,  1.14879958e-01,  8.91619205e-01,\n",
       "        -2.34618127e-01, -9.96822596e-01, -2.53615111e-01,\n",
       "        -1.44733712e-01, -9.68513608e-01,  1.40370861e-01,\n",
       "        -1.89536467e-01, -4.98492211e-01, -9.99954045e-01,\n",
       "         2.33517513e-02,  9.65227962e-01, -8.19566846e-02,\n",
       "         1.14934882e-02, -8.79899919e-01, -2.09031880e-01,\n",
       "         4.23603237e-01,  1.66555177e-02, -8.72587860e-01,\n",
       "         1.33130804e-01, -9.85351130e-02,  9.93177414e-01,\n",
       "        -1.14616215e-01, -7.75194839e-02, -7.75181055e-01,\n",
       "         2.26428211e-01, -8.51583421e-01, -6.77616149e-02,\n",
       "         7.76021242e-01, -9.90014523e-02, -8.35046709e-01,\n",
       "         4.75007445e-01,  1.02763847e-01, -2.65683271e-02,\n",
       "         2.06386037e-02,  9.99977827e-01,  9.70300913e-01,\n",
       "        -6.35065585e-02, -2.19516173e-01,  1.00238100e-01,\n",
       "         1.84620693e-01,  9.91622150e-01, -6.33436963e-02,\n",
       "         8.25868309e-01,  1.04253359e-01, -2.55046546e-01,\n",
       "        -9.98331487e-01,  2.40221154e-02, -3.83492053e-01,\n",
       "        -2.68561453e-01,  2.03543633e-01, -1.02554902e-01,\n",
       "        -3.55072945e-01,  1.61992479e-02, -3.83032858e-03,\n",
       "        -1.16854027e-01,  7.10308403e-02, -7.63069808e-01,\n",
       "         2.34994031e-02, -1.01518422e-01, -9.13765550e-01,\n",
       "        -4.55027036e-02,  8.90291780e-02,  1.61963776e-01,\n",
       "        -9.92105603e-01, -9.72711921e-01,  9.24461246e-01,\n",
       "         9.97751951e-01, -4.61047113e-01,  4.49237287e-01,\n",
       "        -5.60296606e-03, -1.89388879e-02,  1.29915597e-02,\n",
       "        -1.60503145e-02, -9.92161989e-01,  9.38257396e-01,\n",
       "        -9.88109529e-01,  9.23533857e-01, -3.96148749e-02,\n",
       "         6.92319751e-01, -1.73397049e-01,  9.67251301e-01,\n",
       "         1.00317545e-01,  6.50283933e-01, -1.26091301e-01,\n",
       "         3.81713301e-01, -3.80325899e-03,  9.78752911e-01,\n",
       "        -2.07829133e-01,  1.27891079e-04, -7.57094547e-02,\n",
       "        -7.01499134e-02,  1.29837558e-01, -3.11682940e-01,\n",
       "        -9.95366991e-01, -4.78047393e-02,  1.05321914e-01,\n",
       "         6.29579782e-01,  7.71417469e-02,  6.73107579e-02,\n",
       "         9.68865216e-01,  2.89951568e-03,  4.87297848e-02,\n",
       "         1.13123603e-01,  8.73297989e-01, -3.43113281e-02,\n",
       "        -1.80284102e-02, -9.94621217e-02,  9.80276525e-01,\n",
       "         8.87424126e-03,  2.48815775e-01,  3.31447512e-01,\n",
       "         9.78547633e-02,  6.79783404e-01,  4.04622518e-02,\n",
       "         9.99892354e-01,  9.11021709e-01, -4.26748931e-01,\n",
       "        -3.08677793e-01, -9.27197397e-01,  9.27189291e-01,\n",
       "        -1.30905733e-01,  9.24361765e-01,  9.98967886e-01,\n",
       "        -9.94895518e-01, -9.75457430e-02, -1.12360477e-01,\n",
       "         8.05727988e-02,  9.84479010e-01,  1.33155301e-01,\n",
       "        -2.47501694e-02,  9.99324679e-01, -8.44694972e-01,\n",
       "        -9.44435239e-01, -3.21148038e-01, -6.13975704e-01,\n",
       "         4.51112837e-02, -8.63059103e-01, -1.50828809e-01,\n",
       "         3.96113507e-02, -7.65997097e-02,  1.01392518e-03,\n",
       "         8.25803652e-02,  2.41367564e-01, -4.53611091e-02,\n",
       "        -7.11564347e-02,  7.26148561e-02,  9.81311679e-01,\n",
       "        -9.59130108e-01,  9.99756873e-01,  1.49602756e-01,\n",
       "         1.42459080e-01, -8.28650519e-02,  9.86508489e-01,\n",
       "         1.08998984e-01, -9.62126553e-01, -5.80757856e-01,\n",
       "        -2.60392372e-02, -5.88070452e-02,  1.59674048e-01,\n",
       "         2.72896528e-01, -2.73365766e-01,  5.66608459e-02,\n",
       "        -9.99717116e-01, -1.06506102e-01, -1.21046521e-01,\n",
       "        -9.90861058e-01,  9.99642849e-01,  2.24846393e-01,\n",
       "        -9.19380546e-01,  2.29864597e-01, -5.78944027e-01,\n",
       "         8.86653423e-01,  4.88550663e-02, -3.45095694e-02,\n",
       "        -3.43752420e-03,  8.97764266e-01, -8.69690329e-02,\n",
       "         9.96913195e-01, -9.76721570e-02, -3.57538722e-02,\n",
       "         8.94829780e-02, -1.03015751e-01,  9.98572648e-01,\n",
       "         9.62308943e-01, -8.44330609e-01, -2.65076216e-02,\n",
       "         6.40057772e-03,  2.25537807e-01,  5.37402043e-03,\n",
       "        -9.18667376e-01,  1.36114389e-01,  5.42952754e-02,\n",
       "        -2.38197803e-01,  1.98965311e-01,  5.90661108e-01,\n",
       "         6.96617067e-02,  3.68235022e-01,  9.29251552e-01,\n",
       "        -3.07838857e-01,  7.40693733e-02, -2.83886343e-02,\n",
       "        -8.37423429e-02, -3.22652638e-01,  9.99337971e-01,\n",
       "        -2.03171447e-01,  9.79847848e-01, -2.20349580e-01,\n",
       "         9.58206773e-01,  4.46566522e-01,  9.47329998e-01,\n",
       "         8.70917141e-01, -2.36769155e-01,  1.41364075e-02,\n",
       "         8.69914889e-01, -2.95459896e-01,  2.12592885e-01,\n",
       "         8.90934885e-01,  2.36470982e-01,  1.49392515e-01,\n",
       "        -1.89392060e-01,  1.77618623e-01,  1.80689499e-01,\n",
       "         9.88605261e-01, -8.93741786e-01, -6.57466725e-02,\n",
       "        -2.39453409e-02,  9.84788299e-01,  4.80406098e-02,\n",
       "         4.75600287e-02,  1.58554733e-01,  7.54742548e-02,\n",
       "        -1.58316225e-01,  9.62551713e-01, -2.16719106e-01,\n",
       "        -9.89742875e-01, -7.98048079e-02, -8.47630724e-02,\n",
       "         1.29539102e-01,  9.50348899e-02,  8.21275339e-02,\n",
       "        -1.02411754e-01, -2.43212238e-01,  9.86618698e-01,\n",
       "         2.44564321e-02,  3.25726420e-02,  1.31634966e-01,\n",
       "        -1.15653761e-01, -4.89301700e-03,  9.98528898e-01,\n",
       "        -9.06635076e-02,  1.30336329e-01, -2.51226783e-01,\n",
       "         1.99938957e-02, -7.70717785e-02, -9.25431728e-01,\n",
       "        -2.11686566e-01, -4.32602465e-02,  7.50885829e-02,\n",
       "         8.92491266e-03,  7.39345839e-03,  4.93270993e-01,\n",
       "         1.08833872e-01, -9.81241107e-01, -3.27816069e-01,\n",
       "         3.35881233e-01,  1.03341483e-01,  2.32828662e-01,\n",
       "        -1.24425650e-01, -9.75827992e-01,  1.24133211e-02,\n",
       "        -9.97046351e-01, -1.06959738e-01, -2.07887933e-01,\n",
       "         9.39003170e-01,  2.68245846e-01, -9.65325952e-01,\n",
       "         8.68289113e-01, -9.85770464e-01, -6.47883937e-02,\n",
       "        -5.18204153e-01,  2.22023819e-02, -8.24092925e-02,\n",
       "         7.64523745e-02,  5.28805494e-01, -1.64665520e-01,\n",
       "        -1.67733759e-01,  1.95263878e-01, -6.56583458e-02,\n",
       "        -5.54068834e-02,  1.45460032e-02, -6.94071576e-02,\n",
       "         6.62540793e-02, -3.37838888e-01, -3.26270564e-03,\n",
       "         9.31160748e-02,  9.74559486e-01, -6.90148771e-01,\n",
       "         9.59940016e-01, -6.37764037e-01, -3.67367983e-01,\n",
       "        -3.68707776e-02, -4.32362139e-01, -8.25610682e-02,\n",
       "         9.87352788e-01, -3.58427651e-02, -6.19404539e-02,\n",
       "        -4.17431921e-01, -1.32684052e-01, -1.25325546e-01,\n",
       "        -1.34563372e-01,  3.32738757e-01,  4.97882277e-01,\n",
       "        -2.37889290e-02,  1.27032414e-01, -3.02908123e-02,\n",
       "         7.99363628e-02, -4.16497022e-01, -1.09181963e-01,\n",
       "         7.67583400e-02,  1.08720377e-01,  9.03146982e-01,\n",
       "         8.59797895e-01,  6.30147159e-01,  9.10290837e-01,\n",
       "         6.88562095e-01,  2.27025375e-01,  3.04726154e-01,\n",
       "         2.18181778e-02,  7.59273648e-01, -7.86483705e-01,\n",
       "         9.86395955e-01,  6.28675938e-01, -9.10161436e-01,\n",
       "        -9.65585649e-01,  7.53339902e-02,  8.36937502e-02,\n",
       "        -1.44059598e-01, -1.10497763e-02, -9.16745245e-01,\n",
       "        -1.82960019e-01,  5.70296161e-02, -1.36876971e-01,\n",
       "         1.60324767e-01,  9.99613464e-01,  1.67473312e-02,\n",
       "         2.80369103e-01, -8.60125661e-01, -2.31967792e-01,\n",
       "         1.88062429e-01, -9.60462242e-02,  1.31651899e-02,\n",
       "         8.95677805e-01,  1.12855636e-01, -2.90162116e-02,\n",
       "         9.74718273e-01,  1.72097266e-01,  6.39684439e-01,\n",
       "         5.14522716e-02, -1.35673404e-01, -8.86659741e-01,\n",
       "         1.06572688e-01,  2.45612323e-01, -5.70375383e-01,\n",
       "         4.80861105e-02,  9.06781971e-01, -1.05226813e-02,\n",
       "         1.59173273e-02, -6.76006898e-02,  9.92320120e-01,\n",
       "         4.84105982e-02, -1.59600452e-01, -4.11711000e-02,\n",
       "        -4.18284498e-02, -4.48628217e-01, -4.94926840e-01,\n",
       "         5.77201359e-02,  6.83880687e-01,  9.14146960e-01,\n",
       "        -6.20503398e-03,  2.60585815e-01,  9.93166566e-01,\n",
       "         9.90956306e-01, -2.77439713e-01, -1.92655370e-01,\n",
       "         6.24027736e-02,  1.48479983e-01,  3.28795724e-02,\n",
       "         9.03014183e-01, -7.93913007e-01, -9.99833882e-01,\n",
       "         8.94714475e-01, -8.22221696e-01, -9.93023634e-01,\n",
       "         1.25570416e-01,  3.18767548e-01,  2.04114523e-03,\n",
       "        -9.99914646e-01, -2.91604906e-01, -9.98057008e-01,\n",
       "         2.24745162e-02, -9.90033150e-01, -9.99019623e-01,\n",
       "         6.13839269e-01,  6.23649769e-02, -1.51702585e-02,\n",
       "        -1.39499567e-02,  9.03610647e-01,  9.95443106e-01,\n",
       "         7.77770996e-01,  7.13707432e-02,  1.92148071e-02,\n",
       "        -4.27635282e-01,  6.06121086e-02, -5.04037380e-01,\n",
       "         9.76266146e-01, -3.60824652e-02, -1.44494018e-02,\n",
       "        -9.41638231e-01, -9.91448462e-01, -1.47676468e-01,\n",
       "         1.61956877e-01,  1.90013945e-01, -2.20707819e-01,\n",
       "         6.98831439e-01, -1.15667179e-01, -1.22321978e-01,\n",
       "        -9.85032201e-01,  6.11988343e-02,  9.70146954e-01,\n",
       "         7.65576810e-02,  9.97286558e-01, -1.25390112e-01,\n",
       "        -1.40373588e-01, -9.97348428e-01, -9.96985376e-01,\n",
       "         1.37588173e-01, -9.91403461e-01,  7.36417651e-01,\n",
       "        -3.35773304e-02, -9.42393661e-01, -4.01312821e-02,\n",
       "         2.07291856e-01, -1.43676788e-01, -1.93661928e-01,\n",
       "         9.45561975e-02,  4.84949112e-01,  9.86948371e-01,\n",
       "         2.22743616e-01,  9.49871957e-01,  1.98516361e-02,\n",
       "        -2.16030329e-01, -1.47966489e-01, -9.99686658e-01,\n",
       "         9.94199574e-01,  9.61383224e-01,  1.50247514e-01,\n",
       "         9.62567866e-01,  3.06512509e-02,  9.44056585e-02,\n",
       "         1.33240335e-02,  2.82272458e-01, -8.76146793e-01,\n",
       "         2.07563892e-01, -1.03985071e-01, -8.89368132e-02,\n",
       "         2.03973755e-01, -2.34547123e-01,  9.88425780e-03,\n",
       "        -5.17974868e-02, -2.47489482e-01,  5.99764027e-02,\n",
       "         1.38523132e-01,  6.59962744e-02, -1.05322309e-01,\n",
       "         1.29498472e-03,  9.73504603e-01, -4.28298488e-02,\n",
       "        -9.61770475e-01, -9.52090144e-01, -1.52864709e-01,\n",
       "        -7.55819142e-01,  9.67120528e-01, -9.87100482e-01,\n",
       "         9.56209600e-01,  2.38354951e-01, -4.57962334e-01,\n",
       "         9.94464695e-01, -9.09952641e-01,  8.19255710e-02,\n",
       "        -7.00814426e-02, -9.24151301e-01, -1.28064036e-01,\n",
       "        -9.79763329e-01,  9.38648582e-01, -2.32395306e-02,\n",
       "         9.56679434e-02, -9.39789712e-01,  2.01475203e-01,\n",
       "         7.23995090e-01, -2.00643793e-01, -2.74460882e-01]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb80221b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b9fd42c-8f66-4819-9901-78c0caa5d634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vect[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5df556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vect = outputs.last_hidden_state.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8fb5056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9, 768)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0e73a86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.19090897e-01, -7.33323157e-01,  4.11863476e-02, -1.02886045e+00,\n",
       "        7.40690410e-01, -6.67047024e-01,  3.21383923e-01, -3.98489743e-01,\n",
       "       -2.44242266e-01, -3.49172682e-01,  2.56360620e-02,  5.70815623e-01,\n",
       "       -5.08683383e-01, -9.19217691e-02, -9.41551507e-01,  1.66317038e-02,\n",
       "        5.12012959e-01, -2.95386821e-01, -1.08899258e-01,  4.32590902e-01,\n",
       "       -3.99044156e-01, -3.31985265e-01, -3.17970932e-01,  1.34970665e-01,\n",
       "       -7.57174551e-01, -9.24601376e-01,  8.02280232e-02, -2.86633253e-01,\n",
       "       -2.00958177e-02, -7.50293553e-01,  3.42180997e-01,  1.08320720e-01,\n",
       "        4.63421077e-01,  6.65516794e-01,  2.47015461e-01, -1.81869611e-01,\n",
       "       -1.36993432e+00, -6.63018405e-01, -2.67974958e-02,  1.50813743e-01,\n",
       "        1.80872008e-01, -5.75162098e-02, -2.51463413e-01,  6.66169107e-01,\n",
       "        5.74984252e-01,  5.82376719e-01,  8.09811056e-01, -1.66808158e-01,\n",
       "        6.67355895e-01,  6.55739009e-01,  4.71132725e-01,  1.90161258e-01,\n",
       "       -3.09524834e-01, -4.84869033e-01, -4.70822006e-02,  1.71165526e-01,\n",
       "        2.38292068e-01,  5.07407904e-01,  1.41892225e-01,  2.88709432e-01,\n",
       "       -6.57918215e-01,  1.15428865e-02, -3.04581583e-01,  3.36918652e-01,\n",
       "        9.91615653e-02,  1.89620346e-01,  2.92564690e-01,  4.85623509e-01,\n",
       "       -6.17018461e-01,  3.27201396e-01, -2.51279891e-01,  5.10258973e-02,\n",
       "       -5.50548136e-01,  2.06206501e-01,  4.88009423e-01,  5.48868597e-01,\n",
       "        2.18339890e-01,  2.44041141e-02, -8.28183115e-01,  2.79293597e-01,\n",
       "       -1.11947104e-01, -2.78971314e-01,  5.67023754e-02,  6.18878245e-01,\n",
       "        3.02996695e-01,  2.50404924e-01, -1.95466176e-01,  8.89900029e-02,\n",
       "        1.24340437e-01,  2.95745522e-01, -2.74207890e-01, -6.25397503e-01,\n",
       "       -1.14670014e+00, -3.55402917e-01,  7.49810636e-01,  6.28488541e-01,\n",
       "       -1.65459618e-01, -2.64406532e-01, -4.36935067e-01, -5.19071639e-01,\n",
       "        5.37900776e-02, -1.09350786e-01,  3.21262896e-01,  2.32493281e-01,\n",
       "       -3.51141810e-01,  6.07208908e-01,  3.72335434e-01,  2.35175395e+00,\n",
       "       -2.34508902e-01, -2.73464531e-01,  3.66314173e-01,  5.36213577e-01,\n",
       "        4.93477046e-01,  9.80570912e-01, -1.66661471e-01, -4.06893194e-01,\n",
       "        2.22040832e-01, -5.14554739e-01, -5.26531816e-01, -3.94600272e-01,\n",
       "       -1.40883878e-01,  3.09005827e-02, -1.89533323e-01, -9.90885571e-02,\n",
       "        1.01610452e-01,  2.46416107e-02, -8.91984046e-01,  9.74810421e-01,\n",
       "       -3.30821782e-01,  2.41290823e-01, -2.88521916e-01, -4.25933063e-01,\n",
       "        2.57032931e-01,  1.26892507e-01,  6.07741326e-02,  3.31442356e-01,\n",
       "       -9.55883414e-02,  4.91061896e-01,  3.09040636e-01, -5.97573876e-01,\n",
       "        4.93185163e-01, -2.93895304e-01, -3.11446428e-01,  3.60020578e-01,\n",
       "       -5.41787863e-01, -1.89392924e-01, -2.32209206e-01, -4.28023189e-01,\n",
       "        4.25730348e-01,  5.07018715e-02, -2.84487545e-01, -2.13693649e-01,\n",
       "        4.61564124e-01, -6.93787813e-01, -1.15902078e+00,  1.11254704e+00,\n",
       "       -6.56574443e-02,  2.70309120e-01,  7.41076022e-02, -2.43305102e-01,\n",
       "       -5.64757466e-01, -1.91243947e-01,  1.42460346e-01, -3.68381441e-01,\n",
       "       -1.71266422e-01, -1.84488505e-01,  2.30831765e-02, -1.91305578e-03,\n",
       "       -1.76247448e-01,  1.90025032e-01, -7.78303802e-01,  4.62773651e-01,\n",
       "       -7.63312131e-02, -2.98829913e-01, -5.12300909e-01, -1.01242878e-01,\n",
       "       -4.21070457e-01, -1.18942805e-01, -5.13374090e-01,  2.31312573e-01,\n",
       "        2.80465126e-01, -4.97530639e-01,  2.56497040e-02,  2.43661776e-01,\n",
       "        7.46300399e-01,  7.16576949e-02, -1.03734195e-01,  1.79565847e-02,\n",
       "        5.08480787e-01,  5.73672578e-02, -2.36558929e-01, -5.14624476e-01,\n",
       "        2.01674327e-02, -7.13482127e-03,  1.68602183e-01,  5.47205210e-01,\n",
       "        1.11856639e-01, -3.08633775e-01, -5.74770570e-03, -3.07212561e-01,\n",
       "       -5.32724321e-01,  6.29860878e-01,  2.90360093e-01, -1.39395427e-02,\n",
       "       -3.25969368e-01, -7.70635158e-02, -5.29761791e-01, -5.21892786e-01,\n",
       "       -3.19546834e-02,  1.04151908e-02, -2.84068584e-01, -5.44224828e-02,\n",
       "       -3.02860260e-01, -5.77145256e-02,  3.00500661e-01, -2.17143685e-01,\n",
       "       -7.96175361e-01,  9.54183221e-01,  2.88426071e-01, -1.34355575e-01,\n",
       "        1.10287398e-01,  7.99510814e-03, -3.54038447e-01, -2.69711405e-01,\n",
       "       -2.94098914e-01,  4.05707657e-01, -1.06446075e+00,  6.57663286e-01,\n",
       "        3.51362258e-01,  3.59134257e-01,  1.32900560e+00, -6.95064589e-02,\n",
       "       -2.34935209e-01,  2.22255439e-02, -1.47009194e-02,  5.11861205e-01,\n",
       "       -7.62832582e-01,  3.12358141e-01, -2.02669591e-01,  1.44633383e-01,\n",
       "        6.47794724e-01,  5.67262650e-01,  1.97228894e-01,  8.38414192e-01,\n",
       "        6.05815113e-01, -1.85656041e-01,  1.87638521e-01,  1.15443364e-01,\n",
       "       -4.38308418e-01, -6.79578602e-01, -1.89928249e-01, -7.37598300e-01,\n",
       "       -1.26105666e-01,  1.26105472e-01,  1.40020028e-02, -3.68893385e-01,\n",
       "       -1.78726673e-01,  6.06972516e-01,  2.51552999e-01,  3.85915965e-01,\n",
       "        4.09147441e-01, -7.71144331e-01, -1.39700174e-01,  1.30330548e-02,\n",
       "       -7.80160725e-02, -9.11245421e-02, -3.26551378e-01, -2.68048644e-01,\n",
       "        7.98580348e-02, -6.81583434e-02,  2.20539913e-01, -5.21572471e-01,\n",
       "        2.35640317e-01,  6.09970987e-02,  2.16505855e-01, -1.37973160e-01,\n",
       "       -4.49383378e-01, -3.48876685e-01, -1.99134648e-01, -1.01415825e+00,\n",
       "       -2.21535981e-01, -1.45093858e-01,  2.83110261e-01,  4.92120236e-02,\n",
       "       -2.17539653e-01,  2.72050798e-01, -1.77107304e-01,  6.20908216e-02,\n",
       "        1.64016336e-01,  2.88884431e-01,  4.94966149e-01, -2.78520703e-01,\n",
       "       -5.12220979e-01,  3.65002066e-01, -6.05987787e-01,  2.09767580e-01,\n",
       "        7.79121041e-01,  9.55999613e-01,  1.45811796e-01, -8.08935344e-01,\n",
       "       -1.63082778e-03,  3.43741953e-01,  5.26397705e-01, -3.45375314e-02,\n",
       "       -3.24957430e-01, -1.27558887e-01, -4.83288705e-01, -1.92730522e+00,\n",
       "       -4.15446728e-01,  1.77763343e-01, -2.64409482e-02,  1.39274824e+00,\n",
       "        8.11779022e-01,  2.79575855e-01,  4.14651155e-01, -6.22878432e-01,\n",
       "       -5.56880757e-02, -4.28093314e-01, -9.84937608e-01, -6.53061569e-01,\n",
       "       -9.50124562e-01, -1.97339192e-01,  4.65855628e-01, -1.31665245e-01,\n",
       "       -2.65351087e-01,  9.20419767e-02, -3.85825276e-01,  7.46501684e-01,\n",
       "        8.04603100e-01,  2.23187029e-01, -7.45866835e-01,  3.20996344e-02,\n",
       "        9.03871730e-02, -3.88131797e-01,  3.94753933e-01, -5.81341237e-03,\n",
       "        3.17622304e-01, -3.73253763e-01, -5.72241768e-02, -4.43759739e-01,\n",
       "       -3.45621407e-01,  1.58350542e-01,  2.10693553e-01, -6.65850818e-01,\n",
       "       -7.98754990e-01, -4.30579692e-01,  1.88165903e-02,  6.81676492e-02,\n",
       "        9.07087266e-01,  3.27197433e-01,  3.76429737e-01, -2.19895706e-01,\n",
       "        8.69963825e-01, -2.31388420e-01, -8.70261341e-02,  1.87680781e-01,\n",
       "       -2.86042988e-01, -3.15473050e-01, -1.32340938e-01, -7.16268599e-01,\n",
       "       -4.27312814e-02,  2.71294832e-01, -3.99661779e-01, -5.43194562e-02,\n",
       "       -2.66178578e-01, -3.08131546e-01, -6.06120944e-01, -9.31436956e-01,\n",
       "       -2.55191624e-01,  6.44813403e-02,  6.45511985e-01, -4.23290819e-01,\n",
       "       -3.44086915e-01,  3.29971433e-01, -6.55437648e-01,  1.03453100e-02,\n",
       "        2.45296240e-01, -1.02937527e-01,  3.30434442e-01,  4.98220623e-02,\n",
       "        1.66351169e-01,  1.10114120e-01, -9.48979974e-01, -6.85939014e-01,\n",
       "        1.06611483e-01,  5.22445999e-02, -4.79066193e-01,  6.13807961e-02,\n",
       "       -6.70647860e-01, -4.69710119e-02, -2.40168154e-01, -9.46107626e-01,\n",
       "       -1.48086518e-01,  1.85265988e-01,  5.92535436e-01,  4.61531132e-01,\n",
       "        1.14390707e+00, -2.91195899e-01,  5.31299174e-01, -2.22838238e-01,\n",
       "        8.91886115e-01, -3.47899109e-01,  9.04273055e-03, -6.76077664e-01,\n",
       "       -4.17546332e-01, -3.00709188e-01,  1.36906713e-01,  3.43680605e-02,\n",
       "       -1.08953930e-01,  3.19792479e-01, -1.12881161e-01,  1.17747471e-01,\n",
       "        2.97745168e-01, -5.78137815e-01, -1.81032285e-01, -4.14013326e-01,\n",
       "        1.59893382e+00,  2.22292721e-01, -7.02985704e-01, -2.78063506e-01,\n",
       "        3.10641304e-02, -1.99811369e-01,  3.22773188e-01,  3.32415849e-01,\n",
       "       -1.55832455e-01,  3.05377036e-01,  6.46732152e-02, -2.04643205e-01,\n",
       "        1.88198537e-02,  1.63295716e-01, -2.36363143e-01, -4.69310790e-01,\n",
       "        2.00791359e-01, -6.16107941e-01,  2.27964923e-01, -1.20953858e-01,\n",
       "       -5.86040728e-02,  2.44612843e-01, -7.53708929e-02,  2.05836579e-01,\n",
       "        1.97644159e-01, -2.95560658e-01,  4.11466807e-01,  4.83382285e-01,\n",
       "        9.96272027e-01, -2.17976063e-01,  4.44090664e-01, -1.57688349e-01,\n",
       "       -3.72269928e-01, -1.53476506e-01,  2.85165101e-01, -2.52115548e-01,\n",
       "       -1.50127023e-01,  9.44163650e-02,  2.39567995e-01,  1.03748512e+00,\n",
       "       -1.39812395e-01,  6.41139090e-01, -2.10058674e-01, -3.81295770e-01,\n",
       "        1.45871729e-01, -1.01129889e-01,  2.54690111e-01,  1.32619351e-01,\n",
       "       -1.87255353e-01,  1.81770205e-01, -5.36235571e-01, -4.37699020e-01,\n",
       "       -6.83546484e-01,  9.17115510e-01,  1.07073867e+00,  1.46288186e-01,\n",
       "        5.75464606e-01,  1.60835162e-01, -3.65303040e-01,  4.75071847e-01,\n",
       "        7.52434075e-01,  3.99501562e-01,  1.96753711e-01,  1.03613615e+00,\n",
       "        1.99608207e-01, -5.74324846e-01, -4.58782256e-01,  5.62161624e-01,\n",
       "       -3.91148359e-01, -1.02575429e-01,  2.68700331e-01, -4.14083719e-01,\n",
       "        6.44173741e-01,  8.59319627e-01, -4.99055237e-01, -2.03176215e-01,\n",
       "        1.07805550e+00, -5.21331489e-01,  4.71285619e-02,  3.11540961e-01,\n",
       "        6.50681734e-01, -5.21767080e-01, -5.68608344e-02,  5.61376333e-01,\n",
       "        3.64651904e-02,  3.06940466e-01, -2.59617120e-01, -3.98974717e-01,\n",
       "        8.35093379e-01, -2.95549393e-01, -1.02710009e-01, -2.33209386e-01,\n",
       "       -9.15809274e-02,  1.04411706e-01,  8.88958648e-02,  6.91515982e-01,\n",
       "        2.96025157e-01,  9.38912332e-01, -1.46851048e-01,  8.10461789e-02,\n",
       "       -2.12970465e-01,  5.07332124e-02,  3.63452494e-01, -1.37207359e-01,\n",
       "       -1.55390948e-01, -6.29832000e-02, -5.22521138e-02, -6.07111081e-02,\n",
       "       -3.27004671e-01, -1.69576734e-01,  2.25216120e-01,  1.48314834e-01,\n",
       "       -4.04704809e-01,  7.02052891e-01, -1.44559667e-02,  3.48623723e-01,\n",
       "        9.92716104e-02, -5.17628014e-01, -6.15437686e-01, -4.25325222e-02,\n",
       "        4.57385212e-01, -3.50505352e-01, -5.43661952e-01, -7.37386569e-03,\n",
       "        1.39449939e-01,  1.37182921e-01,  2.93755800e-01, -3.71206611e-01,\n",
       "        9.67749432e-02, -7.56329775e-01, -7.60098517e-01,  1.55001104e-01,\n",
       "        6.77773654e-02,  1.02549851e-01, -5.74978292e-01, -8.50322247e-01,\n",
       "       -3.04894671e-02,  5.25673926e-01, -2.11061612e-02,  9.61078778e-02,\n",
       "        1.23887382e-01,  6.44319892e-01, -1.28696346e+01, -5.10796964e-01,\n",
       "       -4.18177843e-02,  1.97124615e-01, -1.87482595e-01, -1.81463629e-01,\n",
       "        2.92318255e-01,  4.03787762e-01, -1.17606759e+00,  6.35513902e-01,\n",
       "       -1.99782848e-02,  2.36403674e-01, -6.50606528e-02,  2.99339414e-01,\n",
       "       -1.42878845e-01,  2.97360420e-01,  9.52432081e-02, -6.91295624e-01,\n",
       "        3.32627535e-01, -5.43744266e-01,  4.54824455e-02, -7.02726990e-02,\n",
       "       -7.55295232e-02,  5.47476709e-02, -8.49769592e-01,  1.16474703e-02,\n",
       "        1.98437497e-01, -2.69175738e-01,  4.75948989e-01, -1.88156664e-01,\n",
       "        6.86618760e-02,  2.39854872e-01,  1.10041179e-01, -5.90847611e-01,\n",
       "       -3.87540817e-01, -5.50198555e-01,  3.91388655e-01, -3.06341983e-03,\n",
       "       -1.13765979e+00,  1.19151938e+00,  4.51939344e-01, -5.59620202e-01,\n",
       "       -6.59001231e-01,  1.44435361e-01, -1.66338757e-02, -2.93715984e-01,\n",
       "        2.51664698e-01, -2.13368803e-01,  2.90596753e-01, -5.33749521e-01,\n",
       "       -1.30674794e-01, -1.24764517e-01, -4.04880226e-01, -7.07071662e-01,\n",
       "        8.95664617e-02,  5.80703855e-01, -2.42062300e-01,  1.11166716e-01,\n",
       "        1.48959744e+00,  1.78534672e-01,  1.93342373e-01,  1.26296088e-01,\n",
       "       -4.06409591e-01, -8.67739141e-01, -2.97106445e-01,  2.18116507e-01,\n",
       "        2.48728395e-02, -6.49318814e-01,  1.39422134e-01,  1.97697952e-01,\n",
       "       -2.31583744e-01, -7.49340534e-01, -7.90919662e-01, -5.35262108e-01,\n",
       "        5.08571982e-01,  2.26379350e-01, -7.72041678e-01, -2.56995082e-01,\n",
       "       -4.12016809e-01, -6.17365062e-01,  2.25936025e-01, -5.38493767e-02,\n",
       "        2.48412177e-01, -1.83965176e-01,  7.67308652e-01,  3.61904949e-01,\n",
       "       -4.10620242e-01, -1.39838129e-01,  1.31519400e-02, -2.60574013e-01,\n",
       "        6.40988469e-01, -2.85406947e-01, -1.64815992e-01,  4.05355990e-01,\n",
       "        1.22749373e-01,  7.69413233e-01, -5.00497401e-01,  2.37367332e-01,\n",
       "       -1.23586252e-01,  3.73328447e-01,  1.03885949e-01,  4.15369689e-01,\n",
       "        1.82607785e-01, -2.70800680e-01, -5.91160774e-01,  6.81385398e-01,\n",
       "        2.99066305e-01,  2.34407514e-01,  7.08126873e-02, -1.57021451e+00,\n",
       "       -1.06122160e+00, -8.07713568e-02,  1.65552631e-01,  3.93758267e-01,\n",
       "        3.79692793e-01, -4.21981990e-01, -2.30427951e-01,  7.26611495e-01,\n",
       "       -7.72286728e-02,  1.08294412e-01, -2.79746838e-02,  4.81794626e-01,\n",
       "        9.83388796e-02,  6.54843807e-01,  9.68296528e-02, -4.33614731e-01,\n",
       "       -5.17641902e-02,  4.47999179e-01, -6.25251770e-01,  4.47464257e-01,\n",
       "        9.60526913e-02, -3.32121342e-01, -5.36553040e-02, -1.45424694e-01,\n",
       "        1.62412837e-01,  5.51311746e-02,  5.07560253e-01, -6.59796596e-01,\n",
       "       -9.60706294e-01, -1.25729114e-01,  2.19414998e-02, -3.03231239e-01,\n",
       "       -6.00605547e-01, -2.02624157e-01,  8.63016248e-01, -2.32709795e-02,\n",
       "       -4.04911876e-01,  1.08882882e-01, -1.95512101e-01, -3.98216993e-02,\n",
       "       -3.23186517e-01,  3.22495075e-03, -2.08704203e-01, -1.81698635e-01,\n",
       "        7.25811005e-01, -1.58972248e-01,  1.09018731e+00, -1.77647591e-01,\n",
       "       -3.82174760e-01,  4.14485067e-01,  2.01470733e-01, -4.62540314e-02,\n",
       "       -1.04628973e-01,  4.01059203e-02,  2.04328030e-01,  9.14968967e-01,\n",
       "       -3.73876780e-01,  2.86054760e-01,  2.79074013e-01, -1.76873773e-01,\n",
       "       -2.52535075e-01,  7.12053835e-01, -3.12981933e-01, -2.53059834e-01,\n",
       "        9.74163637e-02, -5.86532474e-01,  2.53172517e-01, -2.20385775e-01,\n",
       "        2.56479383e-01,  4.20304894e-01, -3.79616618e-02,  6.88989460e-01,\n",
       "       -1.90519020e-01,  8.25907290e-01, -3.30848664e-01, -3.32357734e-03,\n",
       "        9.10613298e-01,  1.43148258e-01,  9.63198543e-02,  7.19097495e-01,\n",
       "        1.91579401e-01, -6.78010225e-01, -1.42363518e-01,  9.95725691e-02,\n",
       "       -8.50408077e-02,  1.78699598e-01, -3.17710042e-01, -2.24339172e-01,\n",
       "       -3.84649873e-01, -8.16263914e-01, -1.10017940e-01, -9.36174989e-01,\n",
       "        2.95259804e-01,  8.07075918e-01,  6.87935174e-01,  3.30626816e-02,\n",
       "       -3.57072264e-01, -4.16904151e-01,  1.59815669e-01,  6.12154782e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vect[0,2]   # esto nos daría el embedding de la palabra \"Quién\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba7a7bf",
   "metadata": {},
   "source": [
    "Otra forma de llamar al pooler_output y last_hidden layer es directamente desde output via indexacion:\n",
    "\n",
    "outputs[0]  : last_hidden_state <br>\n",
    "outputs[1]  : pooler_output <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7069a5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1237,  0.2803,  0.6217,  ..., -0.2897,  0.6623,  0.6892],\n",
       "         [-0.4657,  0.2487, -0.1177,  ...,  0.2439,  0.6109,  0.7491],\n",
       "         [-0.4191, -0.7333,  0.0412,  ..., -0.4169,  0.1598,  0.6122],\n",
       "         ...,\n",
       "         [-0.3142, -0.1232,  0.1890,  ..., -0.1837,  0.8170,  0.3507],\n",
       "         [-0.2474,  0.2841,  0.0095,  ...,  0.0677,  0.5647,  0.1738],\n",
       "         [-0.9872, -0.3595,  0.0244,  ..., -0.2530,  1.1619, -0.2488]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f645c67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.5528e-01,  1.2369e-02, -2.0887e-01, -2.3035e-01,  3.8170e-02,\n",
       "         -2.3398e-01,  8.9570e-02, -9.8485e-01, -1.6933e-02, -3.5385e-01,\n",
       "         -7.1521e-01, -1.9591e-01,  1.0233e-01, -9.8851e-01, -2.3959e-02,\n",
       "          8.3479e-02, -2.7281e-02,  9.9625e-01,  1.4597e-01,  9.7896e-01,\n",
       "          2.5057e-01,  3.7788e-02, -9.9760e-01,  9.5620e-01, -9.9785e-01,\n",
       "          8.4532e-01, -8.5625e-01, -2.7185e-01, -2.5260e-01, -9.9153e-01,\n",
       "          2.5218e-01,  9.7068e-01, -2.7211e-02,  7.1304e-01, -1.1333e-01,\n",
       "          5.9167e-01,  1.4911e-01,  3.0053e-01,  6.4381e-01, -1.9160e-01,\n",
       "         -9.2276e-01, -6.2833e-02, -6.4206e-01,  2.5876e-02, -4.0004e-01,\n",
       "          1.1086e-01, -7.1981e-02,  1.4261e-01, -2.2328e-01, -1.9051e-02,\n",
       "         -2.4323e-02,  8.3193e-02, -3.3971e-03,  9.9894e-01,  2.0373e-02,\n",
       "          9.9780e-01, -1.4740e-01, -9.8730e-01, -5.3113e-03,  9.9613e-01,\n",
       "         -1.2250e-01, -9.8390e-01, -3.0281e-01, -9.6005e-01, -1.1456e-01,\n",
       "          9.0570e-01, -1.7222e-01,  1.8182e-01,  9.3723e-01, -7.2215e-01,\n",
       "         -9.9513e-01,  2.3693e-01,  1.9983e-01,  9.8985e-01,  9.5312e-02,\n",
       "          3.4926e-02,  9.9806e-01, -1.1211e-01, -6.1220e-01,  9.7146e-01,\n",
       "          9.8626e-01,  1.7306e-01,  1.9402e-01,  1.1244e-01, -1.0590e-01,\n",
       "         -1.3580e-01,  1.5379e-03, -1.8391e-01, -9.8632e-01,  9.7555e-01,\n",
       "          9.9777e-01, -3.0926e-02,  4.8757e-02, -2.2701e-01, -3.1931e-01,\n",
       "          9.9565e-01, -3.7903e-01, -1.2024e-01,  2.8837e-03,  9.7878e-01,\n",
       "         -8.9605e-01, -1.7611e-01,  1.0287e-01,  3.4586e-02,  9.9677e-01,\n",
       "         -7.3554e-01, -1.5640e-01,  2.4407e-01, -9.8478e-01,  7.9811e-01,\n",
       "         -9.4489e-01, -9.8366e-01,  3.4827e-02,  3.0859e-02, -4.2955e-02,\n",
       "         -9.8325e-01,  1.4085e-01, -2.1952e-01, -8.6692e-01,  9.3969e-01,\n",
       "          4.7787e-02,  9.9245e-01,  2.3189e-01,  9.4031e-01, -4.9630e-02,\n",
       "         -9.7246e-01, -9.9788e-01,  9.1123e-01, -1.7662e-02,  9.6130e-01,\n",
       "          9.8743e-01, -3.2881e-01, -8.5345e-01, -5.4394e-02, -9.2755e-02,\n",
       "         -9.9756e-01, -9.9890e-01,  1.4333e-01, -1.8457e-01,  9.6945e-02,\n",
       "          9.9606e-01, -9.9082e-01,  9.9745e-01, -7.1253e-02, -9.8409e-01,\n",
       "          9.5906e-01,  9.9669e-01,  1.0789e-02,  1.8599e-01, -7.1889e-01,\n",
       "          9.4045e-01,  5.9157e-01, -4.2075e-02,  3.4593e-02, -6.2092e-02,\n",
       "         -8.6132e-02,  2.0320e-02,  1.6595e-01, -2.1731e-02,  9.9237e-01,\n",
       "          2.3091e-01, -4.5930e-02, -3.7555e-02, -1.6906e-01,  1.4498e-01,\n",
       "         -8.0487e-01,  5.3964e-02, -3.1168e-01, -2.2293e-03,  1.8410e-01,\n",
       "          1.4973e-01, -8.0311e-01, -9.9588e-01,  7.5470e-02, -3.2948e-01,\n",
       "         -4.8281e-03,  9.9253e-01,  1.3224e-01, -8.9530e-01,  9.0730e-02,\n",
       "         -1.9771e-01, -5.7455e-01,  2.6511e-01,  7.8325e-03,  9.6376e-02,\n",
       "          2.6426e-01,  9.2300e-01,  9.8611e-01, -8.3975e-01,  6.7583e-02,\n",
       "         -9.3671e-02, -3.1837e-02,  4.0913e-03,  1.0684e-01,  9.4321e-01,\n",
       "          1.6410e-01,  1.1763e-01,  6.7520e-01, -9.5671e-01,  9.0622e-01,\n",
       "          1.8628e-02, -9.9827e-01, -1.1180e-01,  8.7792e-02, -9.5822e-01,\n",
       "         -5.3619e-02, -7.7642e-01, -8.2842e-01,  8.8776e-01,  9.4449e-02,\n",
       "          7.8955e-02, -8.9596e-01,  7.9141e-01,  9.1814e-04, -9.2540e-01,\n",
       "          1.5821e-01, -2.9516e-01, -9.7482e-02, -2.6023e-01,  8.9354e-01,\n",
       "         -1.6212e-01,  1.0963e-01, -8.7451e-01,  7.7702e-02,  9.8942e-01,\n",
       "         -9.9188e-01,  8.8772e-01,  9.0441e-01, -9.8725e-01,  2.2069e-01,\n",
       "         -9.2657e-01,  9.9452e-01,  1.5980e-01,  9.8409e-02,  8.5473e-01,\n",
       "          2.4419e-01, -1.7898e-02,  4.2681e-03, -9.8699e-01,  8.5855e-01,\n",
       "          1.1542e-02, -4.9898e-02,  8.9705e-03, -9.3826e-01, -9.7739e-01,\n",
       "          8.5920e-01, -1.7708e-01, -7.2107e-01,  1.9595e-01, -1.8715e-01,\n",
       "         -9.7985e-01, -9.7586e-01,  1.0208e-01, -9.5767e-01,  5.9807e-02,\n",
       "         -8.7398e-01,  1.1736e-02,  3.5622e-02,  3.5868e-01,  2.0721e-01,\n",
       "         -5.3984e-01,  1.0925e-01,  2.9120e-03,  7.1897e-01,  9.0938e-01,\n",
       "          1.1488e-01,  8.9162e-01, -2.3462e-01, -9.9682e-01, -2.5362e-01,\n",
       "         -1.4473e-01, -9.6851e-01,  1.4037e-01, -1.8954e-01, -4.9849e-01,\n",
       "         -9.9995e-01,  2.3352e-02,  9.6523e-01, -8.1957e-02,  1.1493e-02,\n",
       "         -8.7990e-01, -2.0903e-01,  4.2360e-01,  1.6656e-02, -8.7259e-01,\n",
       "          1.3313e-01, -9.8535e-02,  9.9318e-01, -1.1462e-01, -7.7519e-02,\n",
       "         -7.7518e-01,  2.2643e-01, -8.5158e-01, -6.7762e-02,  7.7602e-01,\n",
       "         -9.9001e-02, -8.3505e-01,  4.7501e-01,  1.0276e-01, -2.6568e-02,\n",
       "          2.0639e-02,  9.9998e-01,  9.7030e-01, -6.3507e-02, -2.1952e-01,\n",
       "          1.0024e-01,  1.8462e-01,  9.9162e-01, -6.3344e-02,  8.2587e-01,\n",
       "          1.0425e-01, -2.5505e-01, -9.9833e-01,  2.4022e-02, -3.8349e-01,\n",
       "         -2.6856e-01,  2.0354e-01, -1.0255e-01, -3.5507e-01,  1.6199e-02,\n",
       "         -3.8303e-03, -1.1685e-01,  7.1031e-02, -7.6307e-01,  2.3499e-02,\n",
       "         -1.0152e-01, -9.1377e-01, -4.5503e-02,  8.9029e-02,  1.6196e-01,\n",
       "         -9.9211e-01, -9.7271e-01,  9.2446e-01,  9.9775e-01, -4.6105e-01,\n",
       "          4.4924e-01, -5.6030e-03, -1.8939e-02,  1.2992e-02, -1.6050e-02,\n",
       "         -9.9216e-01,  9.3826e-01, -9.8811e-01,  9.2353e-01, -3.9615e-02,\n",
       "          6.9232e-01, -1.7340e-01,  9.6725e-01,  1.0032e-01,  6.5028e-01,\n",
       "         -1.2609e-01,  3.8171e-01, -3.8033e-03,  9.7875e-01, -2.0783e-01,\n",
       "          1.2789e-04, -7.5709e-02, -7.0150e-02,  1.2984e-01, -3.1168e-01,\n",
       "         -9.9537e-01, -4.7805e-02,  1.0532e-01,  6.2958e-01,  7.7142e-02,\n",
       "          6.7311e-02,  9.6887e-01,  2.8995e-03,  4.8730e-02,  1.1312e-01,\n",
       "          8.7330e-01, -3.4311e-02, -1.8028e-02, -9.9462e-02,  9.8028e-01,\n",
       "          8.8742e-03,  2.4882e-01,  3.3145e-01,  9.7855e-02,  6.7978e-01,\n",
       "          4.0462e-02,  9.9989e-01,  9.1102e-01, -4.2675e-01, -3.0868e-01,\n",
       "         -9.2720e-01,  9.2719e-01, -1.3091e-01,  9.2436e-01,  9.9897e-01,\n",
       "         -9.9490e-01, -9.7546e-02, -1.1236e-01,  8.0573e-02,  9.8448e-01,\n",
       "          1.3316e-01, -2.4750e-02,  9.9932e-01, -8.4469e-01, -9.4444e-01,\n",
       "         -3.2115e-01, -6.1398e-01,  4.5111e-02, -8.6306e-01, -1.5083e-01,\n",
       "          3.9611e-02, -7.6600e-02,  1.0139e-03,  8.2580e-02,  2.4137e-01,\n",
       "         -4.5361e-02, -7.1156e-02,  7.2615e-02,  9.8131e-01, -9.5913e-01,\n",
       "          9.9976e-01,  1.4960e-01,  1.4246e-01, -8.2865e-02,  9.8651e-01,\n",
       "          1.0900e-01, -9.6213e-01, -5.8076e-01, -2.6039e-02, -5.8807e-02,\n",
       "          1.5967e-01,  2.7290e-01, -2.7337e-01,  5.6661e-02, -9.9972e-01,\n",
       "         -1.0651e-01, -1.2105e-01, -9.9086e-01,  9.9964e-01,  2.2485e-01,\n",
       "         -9.1938e-01,  2.2986e-01, -5.7894e-01,  8.8665e-01,  4.8855e-02,\n",
       "         -3.4510e-02, -3.4375e-03,  8.9776e-01, -8.6969e-02,  9.9691e-01,\n",
       "         -9.7672e-02, -3.5754e-02,  8.9483e-02, -1.0302e-01,  9.9857e-01,\n",
       "          9.6231e-01, -8.4433e-01, -2.6508e-02,  6.4006e-03,  2.2554e-01,\n",
       "          5.3740e-03, -9.1867e-01,  1.3611e-01,  5.4295e-02, -2.3820e-01,\n",
       "          1.9897e-01,  5.9066e-01,  6.9662e-02,  3.6824e-01,  9.2925e-01,\n",
       "         -3.0784e-01,  7.4069e-02, -2.8389e-02, -8.3742e-02, -3.2265e-01,\n",
       "          9.9934e-01, -2.0317e-01,  9.7985e-01, -2.2035e-01,  9.5821e-01,\n",
       "          4.4657e-01,  9.4733e-01,  8.7092e-01, -2.3677e-01,  1.4136e-02,\n",
       "          8.6991e-01, -2.9546e-01,  2.1259e-01,  8.9093e-01,  2.3647e-01,\n",
       "          1.4939e-01, -1.8939e-01,  1.7762e-01,  1.8069e-01,  9.8861e-01,\n",
       "         -8.9374e-01, -6.5747e-02, -2.3945e-02,  9.8479e-01,  4.8041e-02,\n",
       "          4.7560e-02,  1.5855e-01,  7.5474e-02, -1.5832e-01,  9.6255e-01,\n",
       "         -2.1672e-01, -9.8974e-01, -7.9805e-02, -8.4763e-02,  1.2954e-01,\n",
       "          9.5035e-02,  8.2128e-02, -1.0241e-01, -2.4321e-01,  9.8662e-01,\n",
       "          2.4456e-02,  3.2573e-02,  1.3163e-01, -1.1565e-01, -4.8930e-03,\n",
       "          9.9853e-01, -9.0664e-02,  1.3034e-01, -2.5123e-01,  1.9994e-02,\n",
       "         -7.7072e-02, -9.2543e-01, -2.1169e-01, -4.3260e-02,  7.5089e-02,\n",
       "          8.9249e-03,  7.3935e-03,  4.9327e-01,  1.0883e-01, -9.8124e-01,\n",
       "         -3.2782e-01,  3.3588e-01,  1.0334e-01,  2.3283e-01, -1.2443e-01,\n",
       "         -9.7583e-01,  1.2413e-02, -9.9705e-01, -1.0696e-01, -2.0789e-01,\n",
       "          9.3900e-01,  2.6825e-01, -9.6533e-01,  8.6829e-01, -9.8577e-01,\n",
       "         -6.4788e-02, -5.1820e-01,  2.2202e-02, -8.2409e-02,  7.6452e-02,\n",
       "          5.2881e-01, -1.6467e-01, -1.6773e-01,  1.9526e-01, -6.5658e-02,\n",
       "         -5.5407e-02,  1.4546e-02, -6.9407e-02,  6.6254e-02, -3.3784e-01,\n",
       "         -3.2627e-03,  9.3116e-02,  9.7456e-01, -6.9015e-01,  9.5994e-01,\n",
       "         -6.3776e-01, -3.6737e-01, -3.6871e-02, -4.3236e-01, -8.2561e-02,\n",
       "          9.8735e-01, -3.5843e-02, -6.1940e-02, -4.1743e-01, -1.3268e-01,\n",
       "         -1.2533e-01, -1.3456e-01,  3.3274e-01,  4.9788e-01, -2.3789e-02,\n",
       "          1.2703e-01, -3.0291e-02,  7.9936e-02, -4.1650e-01, -1.0918e-01,\n",
       "          7.6758e-02,  1.0872e-01,  9.0315e-01,  8.5980e-01,  6.3015e-01,\n",
       "          9.1029e-01,  6.8856e-01,  2.2703e-01,  3.0473e-01,  2.1818e-02,\n",
       "          7.5927e-01, -7.8648e-01,  9.8640e-01,  6.2868e-01, -9.1016e-01,\n",
       "         -9.6559e-01,  7.5334e-02,  8.3694e-02, -1.4406e-01, -1.1050e-02,\n",
       "         -9.1675e-01, -1.8296e-01,  5.7030e-02, -1.3688e-01,  1.6032e-01,\n",
       "          9.9961e-01,  1.6747e-02,  2.8037e-01, -8.6013e-01, -2.3197e-01,\n",
       "          1.8806e-01, -9.6046e-02,  1.3165e-02,  8.9568e-01,  1.1286e-01,\n",
       "         -2.9016e-02,  9.7472e-01,  1.7210e-01,  6.3968e-01,  5.1452e-02,\n",
       "         -1.3567e-01, -8.8666e-01,  1.0657e-01,  2.4561e-01, -5.7038e-01,\n",
       "          4.8086e-02,  9.0678e-01, -1.0523e-02,  1.5917e-02, -6.7601e-02,\n",
       "          9.9232e-01,  4.8411e-02, -1.5960e-01, -4.1171e-02, -4.1828e-02,\n",
       "         -4.4863e-01, -4.9493e-01,  5.7720e-02,  6.8388e-01,  9.1415e-01,\n",
       "         -6.2050e-03,  2.6059e-01,  9.9317e-01,  9.9096e-01, -2.7744e-01,\n",
       "         -1.9266e-01,  6.2403e-02,  1.4848e-01,  3.2880e-02,  9.0301e-01,\n",
       "         -7.9391e-01, -9.9983e-01,  8.9471e-01, -8.2222e-01, -9.9302e-01,\n",
       "          1.2557e-01,  3.1877e-01,  2.0411e-03, -9.9991e-01, -2.9160e-01,\n",
       "         -9.9806e-01,  2.2475e-02, -9.9003e-01, -9.9902e-01,  6.1384e-01,\n",
       "          6.2365e-02, -1.5170e-02, -1.3950e-02,  9.0361e-01,  9.9544e-01,\n",
       "          7.7777e-01,  7.1371e-02,  1.9215e-02, -4.2764e-01,  6.0612e-02,\n",
       "         -5.0404e-01,  9.7627e-01, -3.6082e-02, -1.4449e-02, -9.4164e-01,\n",
       "         -9.9145e-01, -1.4768e-01,  1.6196e-01,  1.9001e-01, -2.2071e-01,\n",
       "          6.9883e-01, -1.1567e-01, -1.2232e-01, -9.8503e-01,  6.1199e-02,\n",
       "          9.7015e-01,  7.6558e-02,  9.9729e-01, -1.2539e-01, -1.4037e-01,\n",
       "         -9.9735e-01, -9.9699e-01,  1.3759e-01, -9.9140e-01,  7.3642e-01,\n",
       "         -3.3577e-02, -9.4239e-01, -4.0131e-02,  2.0729e-01, -1.4368e-01,\n",
       "         -1.9366e-01,  9.4556e-02,  4.8495e-01,  9.8695e-01,  2.2274e-01,\n",
       "          9.4987e-01,  1.9852e-02, -2.1603e-01, -1.4797e-01, -9.9969e-01,\n",
       "          9.9420e-01,  9.6138e-01,  1.5025e-01,  9.6257e-01,  3.0651e-02,\n",
       "          9.4406e-02,  1.3324e-02,  2.8227e-01, -8.7615e-01,  2.0756e-01,\n",
       "         -1.0399e-01, -8.8937e-02,  2.0397e-01, -2.3455e-01,  9.8843e-03,\n",
       "         -5.1797e-02, -2.4749e-01,  5.9976e-02,  1.3852e-01,  6.5996e-02,\n",
       "         -1.0532e-01,  1.2950e-03,  9.7350e-01, -4.2830e-02, -9.6177e-01,\n",
       "         -9.5209e-01, -1.5286e-01, -7.5582e-01,  9.6712e-01, -9.8710e-01,\n",
       "          9.5621e-01,  2.3835e-01, -4.5796e-01,  9.9446e-01, -9.0995e-01,\n",
       "          8.1926e-02, -7.0081e-02, -9.2415e-01, -1.2806e-01, -9.7976e-01,\n",
       "          9.3865e-01, -2.3240e-02,  9.5668e-02, -9.3979e-01,  2.0148e-01,\n",
       "          7.2400e-01, -2.0064e-01, -2.7446e-01]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5bb9d3-71d9-4796-a8d7-6544c0d4549a",
   "metadata": {},
   "source": [
    "Y esto?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d5277b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0608,  0.2993,  0.0115,  ...,  0.0999,  0.0082, -0.1987],\n",
       "          [ 0.5044,  1.7119, -0.6341,  ...,  0.2854,  0.3628,  1.0462],\n",
       "          [-0.7312, -0.3984, -0.7442,  ..., -1.3566,  0.2925,  0.2997],\n",
       "          ...,\n",
       "          [ 0.6574,  0.5871, -1.1026,  ...,  0.2151, -0.7084,  0.7364],\n",
       "          [ 0.2365, -0.1930, -1.0301,  ...,  0.0329,  0.4225, -0.7136],\n",
       "          [ 0.1659,  0.0441,  0.0766,  ..., -0.2411,  0.4139,  0.1342]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[[ 0.0181, -0.1076,  0.0097,  ..., -0.0430, -0.0142, -0.2207],\n",
       "          [ 0.4965,  1.4999, -0.7707,  ...,  0.5553,  0.0043,  1.2468],\n",
       "          [-0.4535, -0.6909, -0.4555,  ..., -1.7199,  0.2181, -0.2042],\n",
       "          ...,\n",
       "          [ 0.9583,  0.6662, -1.0942,  ...,  0.0871, -0.7676,  0.8305],\n",
       "          [ 0.1050, -0.5544, -1.0068,  ...,  0.0138,  0.4663, -0.7715],\n",
       "          [ 0.1488,  0.0790, -0.1097,  ..., -0.4080,  0.3653,  0.5044]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[[ 0.1043, -0.1069, -0.0957,  ..., -0.1605,  0.1473, -0.3970],\n",
       "          [ 0.0473,  1.0963, -1.1150,  ...,  0.6021, -0.5058,  1.1164],\n",
       "          [-0.4371, -0.9653, -0.0097,  ..., -1.2727, -0.3911, -0.4583],\n",
       "          ...,\n",
       "          [ 0.5990,  0.6320, -0.9506,  ...,  0.2922, -0.6147,  0.8743],\n",
       "          [ 0.0414, -0.3977, -0.8901,  ..., -0.0199,  0.3218, -0.8195],\n",
       "          [ 0.4116,  0.2776,  0.1881,  ..., -0.4943,  0.2259, -0.0793]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[[-0.3306, -0.0641,  0.0586,  ..., -0.3586,  0.3236, -0.2949],\n",
       "          [ 0.1165,  1.3847, -0.6565,  ...,  0.6473, -0.5877,  1.2650],\n",
       "          [-0.0798, -0.9199,  0.2308,  ..., -1.3246, -0.7255, -0.2177],\n",
       "          ...,\n",
       "          [ 0.2159,  0.7803, -0.7006,  ...,  0.2518, -0.7046,  1.0523],\n",
       "          [-0.0226, -0.2012, -0.4791,  ...,  0.3072, -0.1444, -0.9740],\n",
       "          [ 0.1144,  0.4596,  0.1403,  ..., -0.4678,  0.2280, -0.2170]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[[-0.5059, -0.3326,  0.4700,  ..., -0.4508,  0.1426, -0.1788],\n",
       "          [-0.0332,  1.1284, -0.0907,  ...,  0.8935, -0.3595,  0.9571],\n",
       "          [ 0.1783, -1.3292,  0.6176,  ..., -0.9731, -0.3017,  0.1022],\n",
       "          ...,\n",
       "          [-0.1328, -0.0092, -0.2342,  ...,  0.1854, -0.0098,  1.2672],\n",
       "          [-0.0429, -0.3709, -0.1281,  ...,  0.5592, -0.2288, -0.9795],\n",
       "          [ 0.3948, -0.0163,  0.4307,  ..., -0.5427,  0.1642, -0.3836]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[[-0.6968, -0.2663,  0.2159,  ..., -0.8563,  0.1483,  0.0499],\n",
       "          [-0.0271,  0.8916, -0.1461,  ...,  0.6810,  0.0386,  1.3053],\n",
       "          [ 0.1561, -1.1168,  0.1628,  ..., -1.0569,  0.2775,  0.4480],\n",
       "          ...,\n",
       "          [-0.7061,  0.1963, -0.2042,  ..., -0.2353,  0.4493,  0.9169],\n",
       "          [-0.2406, -0.3166, -0.1502,  ..., -0.2156, -0.1463, -0.8138],\n",
       "          [ 0.4802,  0.0144,  0.1236,  ..., -0.5902,  0.1434, -0.0752]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[[-0.4083, -0.4251,  0.4448,  ..., -0.7379,  0.0194,  0.0653],\n",
       "          [ 0.0885,  0.2956,  0.1536,  ...,  0.6529,  0.0145,  0.9314],\n",
       "          [ 0.2648, -1.4518,  0.2712,  ..., -0.9393,  0.2453,  0.3616],\n",
       "          ...,\n",
       "          [-0.7018,  0.1229,  0.0871,  ..., -0.3768,  0.8822,  0.6812],\n",
       "          [-0.1943, -0.2484, -0.0378,  ..., -0.1963,  0.1854, -0.6277],\n",
       "          [-0.0750, -0.0957, -0.1416,  ..., -0.5696,  0.3093, -0.0532]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[[ 0.0207, -0.2146,  0.4922,  ..., -0.7480,  0.1034,  0.4806],\n",
       "          [ 0.1456,  0.2713,  0.4480,  ...,  0.8693,  0.4132,  1.0908],\n",
       "          [-0.4951, -1.8097,  1.1180,  ..., -0.5572, -0.3359,  0.5252],\n",
       "          ...,\n",
       "          [-0.8921, -0.0708,  0.0584,  ..., -0.1703,  1.1100,  0.7955],\n",
       "          [-0.2942,  0.0353,  0.2268,  ..., -0.2683,  0.1920, -0.2662],\n",
       "          [-0.0024,  0.0281, -0.1364,  ..., -0.2930,  0.3005,  0.0337]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[[ 1.0580e-01,  3.1153e-01,  4.5195e-01,  ..., -6.1409e-01,\n",
       "            2.5671e-01,  2.8353e-01],\n",
       "          [ 7.9980e-02,  7.8049e-01,  3.6350e-01,  ...,  6.2933e-01,\n",
       "            3.0198e-01,  9.2505e-01],\n",
       "          [-2.3318e-01, -1.7653e+00,  5.9700e-01,  ..., -2.1991e-01,\n",
       "            5.5552e-03,  5.8612e-01],\n",
       "          ...,\n",
       "          [-1.1045e+00,  2.7394e-02, -2.9455e-02,  ..., -2.6397e-01,\n",
       "            1.1165e+00,  5.0499e-01],\n",
       "          [-1.2087e-01,  6.3717e-01,  1.8023e-01,  ..., -2.0041e-01,\n",
       "            5.2424e-01, -2.5031e-01],\n",
       "          [-1.7494e-02,  4.0796e-04, -3.8735e-03,  ..., -1.1344e-01,\n",
       "            5.3749e-03, -7.1622e-02]]], grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[[ 0.0940,  0.5585,  0.4514,  ..., -0.4928,  0.6419,  0.4978],\n",
       "          [-0.1626,  1.0802, -0.0170,  ...,  0.7644,  0.8830,  1.5876],\n",
       "          [-0.3222, -1.8629,  0.9668,  ..., -0.8411, -0.0283,  0.7657],\n",
       "          ...,\n",
       "          [-1.2856,  0.1763, -0.1200,  ..., -0.4085,  1.1574,  0.7303],\n",
       "          [-0.2969,  1.0408, -0.1954,  ..., -0.1053,  0.5946, -0.4147],\n",
       "          [ 0.0044,  0.0377, -0.0654,  ..., -0.1082, -0.0120, -0.0725]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[[ 0.3652,  0.4774,  0.4451,  ..., -0.2223,  0.3103,  0.6043],\n",
       "          [-0.5683,  0.9167,  0.0394,  ...,  0.6335,  0.7695,  1.4511],\n",
       "          [-0.2780, -1.1997,  0.4220,  ..., -0.3790,  0.1355,  0.8063],\n",
       "          ...,\n",
       "          [-1.0104,  0.1470,  0.0802,  ..., -0.4061,  1.1102,  0.5280],\n",
       "          [-0.2325,  0.9078,  0.0046,  ..., -0.0217,  0.5461, -0.1169],\n",
       "          [ 0.0417,  0.0127,  0.0147,  ..., -0.0536, -0.0133, -0.0636]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[[ 3.7468e-01,  5.4335e-01,  6.9224e-01,  ..., -3.1812e-01,\n",
       "            5.6896e-01,  7.3585e-01],\n",
       "          [-2.3994e-01,  6.8969e-01,  2.8133e-01,  ...,  6.3491e-01,\n",
       "            7.2759e-01,  9.1228e-01],\n",
       "          [-2.5194e-01, -9.7642e-01,  7.2050e-01,  ...,  3.7923e-04,\n",
       "            4.4741e-02,  8.6301e-01],\n",
       "          ...,\n",
       "          [-7.0167e-01,  4.2465e-03,  5.3665e-01,  ..., -4.1478e-01,\n",
       "            1.3309e+00,  3.8026e-01],\n",
       "          [-1.1598e-01,  7.2518e-01,  2.3942e-01,  ...,  1.4962e-01,\n",
       "            6.7391e-01,  5.1359e-02],\n",
       "          [ 2.6372e-02,  2.1763e-02,  7.3815e-03,  ..., -4.1155e-02,\n",
       "            9.8487e-03, -5.6295e-02]]], grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[[ 0.1237,  0.2803,  0.6217,  ..., -0.2897,  0.6623,  0.6892],\n",
       "          [-0.4657,  0.2487, -0.1177,  ...,  0.2439,  0.6109,  0.7491],\n",
       "          [-0.4191, -0.7333,  0.0412,  ..., -0.4169,  0.1598,  0.6122],\n",
       "          ...,\n",
       "          [-0.3142, -0.1232,  0.1890,  ..., -0.1837,  0.8170,  0.3507],\n",
       "          [-0.2474,  0.2841,  0.0095,  ...,  0.0677,  0.5647,  0.1738],\n",
       "          [-0.9872, -0.3595,  0.0244,  ..., -0.2530,  1.1619, -0.2488]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c24cb345-7ed8-469c-ba17-a06e5477037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs[2])\n",
    "len(outputs[2][0])\n",
    "len(outputs[2][0][0])\n",
    "len(outputs[2][0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f148ea89-feb1-4e74-a968-7f785865a5b5",
   "metadata": {},
   "source": [
    "Vemos que output[2] entrega los embeddings de todas las capas, no solo de la última"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9455646a",
   "metadata": {},
   "source": [
    "Veamos que hace BETR en caso de polisemia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97083ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'Me senté en un banco de la plaza a comer un pan y luego fui al banco a cobrar un cheque. Pero estaban asaltando el banco. '\n",
    "inputs = tokenizer(texto, return_tensors=\"pt\") \n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9910a4e-de8e-4f9e-849d-898b9e722dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] Me senté'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs['input_ids'][0][0:4])\n",
    "# 6067 es el token banco, ver más arriba.... ojo con la indexación porque \"senté\" me lo descompone en dos tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a0a81a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vect = outputs.last_hidden_state.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94a41b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    4,  1369,  1823, 30958,  1036,  1049,  6067,  1008,  1030,  7987,\n",
       "          1013,  2073,  1049,  3231,  1042,  2475,  3893,  1091,  6067,  1013,\n",
       "         15925,  1049, 11618,  1009,  1448,  3760,  8427,  2364,  1040,  6067,\n",
       "          1009,     5]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c365da7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banco\n",
      "banco\n",
      "banco\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(inputs['input_ids'][0][6:7]))   # 6\n",
    "print(tokenizer.decode(inputs['input_ids'][0][18:19]))  # 18\n",
    "print(tokenizer.decode(inputs['input_ids'][0][29:30]))   # 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2c7c2a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2677203 , -0.48607674, -0.12032992,  0.4573033 ,  0.5840764 ,\n",
       "       -0.04971152, -0.01168296, -0.12951699, -0.6504211 ], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vect[0][6][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ee445cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09472138, -0.41395518,  0.15831521,  0.03767878, -0.17275007,\n",
       "       -0.04856254,  0.6763493 , -0.06454432, -0.11978582], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vect[0][18][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00c0414e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12802929, -0.27143663, -0.17953737,  0.29155675, -0.33914167,\n",
       "        0.08626595,  0.23380855, -0.25298792, -0.11596245], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vect[0][29][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80211354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06eb7503",
   "metadata": {},
   "source": [
    "Pese a que son la misma palabra, las representaciones son distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1acd019e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity for  *similar*  meanings:  0.92\n",
      "Vector similarity for *different* meanings:  0.86\n",
      "Vector similarity for *different* meanings:  0.88\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "diff_bank1 = 1 - cosine(word_vect[0][6], word_vect[0][18])\n",
    "diff_bank2 = 1 - cosine(word_vect[0][6], word_vect[0][29])\n",
    "same_bank = 1 - cosine(word_vect[0][18], word_vect[0][29])\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank1)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113980ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc50c7eb-2eaa-4b09-8d73-5d69cda0ac75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e60991-3e24-4149-bf05-16d236479ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
